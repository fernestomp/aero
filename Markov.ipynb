{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "#%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "#para encontrar las coordenadas mas cercanas a un punto\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "import ipynb.fs.defs.my_funcs_clusters as myfunc\n",
    "# noinspection PyCompatibility\n",
    "import pathlib\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funciones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def calculate_vectorprob(row):\n",
    "    \"\"\"\n",
    "    la funcion se aplica fila por fila\n",
    "    se suman todos los valores por fila y se divide entre cada valor, luego se multiplica por 100\n",
    "    Compute the probabability of every row.\n",
    "\n",
    "    usage: mprob = dfMaTra.apply(calculate_vectorprob, axis=1)\n",
    "            mprob.rename(index=idxclnames,inplace=True)\n",
    "    :param row: row number\n",
    "    :return: probabilities matrix\n",
    "    \"\"\"\n",
    "    return row.astype(float)/row.sum()*100\n",
    "\n",
    "def group_state_values(statenum,df):\n",
    "    \"\"\"\n",
    "Agrupa los valores con datos diferentes a nan de un estado en particular. Los datos se agregan a una lista hasta\n",
    "que salta a otro estado, con esto se puede saber cuanto tiempo duro en un estado.\n",
    "\n",
    "    Inputs:\n",
    "            statenum: numero de estado, empieza en 1\n",
    "            dfclvp: dataframe con los clusters separados de vv y pw\n",
    "    Outputs:\n",
    "            lista_valores_estado: una lista con los valores del estado agrupados\n",
    "    \"\"\"\n",
    "    #va a buscar renglon por renglon si el valor es nan y\n",
    "    #va a agrupar los valores que no son nan junto con su timestamp\n",
    "    statenum ='C'+str(statenum)\n",
    "    idx =  df[statenum].first_valid_index() #primer indice que no tiene valores nan\n",
    "    lista_valores_estado=[] #contiene los valores agrupados de tiempo vv y pw\n",
    "    row_values=[]# lista temporal para agrupar los valores de tiempo vv y pw\n",
    "    idxw=0 #indice exclusivo para el ciclo for\n",
    "    while not idxw ==  df.index[-1]: #si el indice ya llego a la ultima fila\n",
    "\n",
    "        for row in df[statenum][idx:].itertuples(): #empieza en el ultimo indice que no tuvo valores\n",
    "            if not np.isnan(row.vViento):\n",
    "                row_values.append([row[0],row.vViento,row.Pw])\n",
    "            #si el valor es nan y row_values tiene elementos significa que\n",
    "            #ya tomo todos los valores del estado y se brinco a otro\n",
    "            if np.isnan(row.vViento) and len(row_values)>0:\n",
    "                idx=row[0]\n",
    "                lista_valores_estado.append(row_values.copy())\n",
    "                row_values.clear()\n",
    "                break\n",
    "            idxw =row[0]#para saber cuando llega al ultimo indice\n",
    "    return lista_valores_estado\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## de matriz (dataframe) a vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# def mat_to_vector(df):\n",
    "#     \"\"\"\n",
    "#     #convertir de matriz a vector  (debe ser igual que kmeans_labels)\n",
    "#     #tomo el dataframe con los estados ya indicados y la convierto a vector ignorando\n",
    "#     #en este caso ceros\n",
    "#     :param df:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     vect_states= []\n",
    "#     for row in range(len(df)):\n",
    "#         clust = np.argwhere(df.iloc[row].notnull().values)[0][0]\n",
    "#         vect_states.append(clust)\n",
    "#         #else:\n",
    "#         #es una fila de ceros, entonces se agrega un cero, así si queda igual\n",
    "#         #que kmeans labels y los otros codigos para hacer la matriz de transicion\n",
    "#         #pero quiero esto?, no, no lo quiero por que no quiero que de un estado x\n",
    "#         #se regrese al estado cero solo porque no hay datos, pero de todos modos lo hago\n",
    "#         #vect_states.append(0)\n",
    "#     return vect_states\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transition matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def transition_matrix(transitions):\n",
    "    \"\"\"\n",
    "    stack overflow, mas elegante\n",
    "    the following code takes a list such as\n",
    "    [1,1,2,6,8,5,5,7,8,8,1,1,4,5,5,0,0,0,1,1,4,4,5,1,3,3,4,5,4,1,1]\n",
    "    with states labeled as successive integers starting with 0\n",
    "    and returns a transition matrix, M,\n",
    "    where M[i][j] is the probability of transitioning from i to j\n",
    "    Test:\n",
    "    t = [1,1,2,6,8,5,5,7,8,8,1,1,4,5,5,0,0,0,1,1,4,4,5,1,3,3,4,5,4,1,1]\n",
    "    m = transition_matrix(vect_states)\n",
    "    for row in m: print(' '.join('{0:.4f}'.format(x) for x in row))\n",
    "\n",
    "    :param transitions: list with transitions\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = 1+ max(transitions) #number of states\n",
    "\n",
    "    M = [[0]*n for _ in range(n)]\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'ipynb.fs.defs.my_funcs_clusters' (C:\\Users\\mungu\\Documents\\GitHub\\aero\\my_funcs_clusters.ipynb)>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(myfunc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ###########################################configuración\n",
    "# columns_to_use = [0,1,3,6]\n",
    "# columns_id =['day','hour','wdir','vwind']\n",
    "# home = str(pathlib.Path.home()) #user directory\n",
    "# xlsPath = home + '\\\\Dropbox\\\\Doctorado\\\\Documentos\\\\datos\\\\datos bcs\\\\DP-PB01-2005.xlsx'\n",
    "# xlsPathMfgCurve = home + '\\\\Dropbox\\\\Doctorado\\\\Python\\\\aero\\\\Curva de potencia vestas 90.xlsx'\n",
    "# dir_format= 'deg'\n",
    "# year = '2005' #data year\n",
    "# ########################################################\n",
    "# #imprimir a consola\n",
    "# os.write(1, b\"Inciando procesamiento de datos...\\n\")\n",
    "#\n",
    "# dataVDxls = pd.read_excel(xlsPath,usecols=columns_to_use,dtype={'DIA' : str, 'HORA':str})\n",
    "# dataVDxls.columns =columns_id\n",
    "# #agrego la columna de potencia instantanea sin filtrar\n",
    "# #dataVPxls['Pw']= (dataVPxls.iloc[1:,1].values-dataVPxls.iloc[0:-1,1]) * np.pi*45**2\n",
    "# print('Total de registros: ' + str(len(dataVDxls)))\n",
    "# #dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0,names=['pw'])#cambio esto en la nueva version\n",
    "# dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0)\n",
    "# dfMfgCurve.columns = ['pw']\n",
    "# #marcando los datos faltantes asignando un nan a la fila completa\n",
    "# datamk = dataVDxls\n",
    "# datamk.loc[datamk.isnull().any(axis=1), :] = np.nan\n",
    "# #numero de filas sin datos\n",
    "# print('Numero de filas sin datos')\n",
    "# print(datamk.loc[datamk.isnull().any(axis=1), :].isnull().sum())\n",
    "#\n",
    "# #eliminando filas con NaN\n",
    "# cleanData = datamk.dropna()\n",
    "#\n",
    "#\n",
    "# #datos direccion velocidad\n",
    "# #print(len(dataVP))\n",
    "# #print(len(dataDir))\n",
    "# #dataDV = pd.concat([dataDir,dataVP.vViento],axis=1)\n",
    "# #dataVD = pd.concat([dataVP.vViento,dataDir,axis=1)\n",
    "# #dataVcD =pd.concat([dataDir,df_comp_vel],axis=1)\n",
    "# #change hour 24:00 to 00:00\n",
    "# dataVDxls['hour']=dataVDxls['hour'].str.replace('2400','0000')\n",
    "# dataVDxls['timeStamp']= dataVDxls.apply(lambda x: myfunc.daymin2date(year,x.day, x.hour), axis=1)\n",
    "# dataVDxls.set_index('timeStamp',inplace=True,verify_integrity = True)\n",
    "# dfWD = dataVDxls.drop(columns=['day','hour'])\n",
    "# dfWD.index =pd.to_datetime(dfWD.index,dayfirst=True)\n",
    "# del dataVDxls\n",
    "# #CHECK THE DIRECTION OF THE ANEMOMETER\n",
    "# if dir_format == 'rad':\n",
    "#     direcvrad= np.deg2rad(dfWD['wdir'].values)\n",
    "#     vecVel = [-np.sin(direcvrad)*dfWD['vwind'].values,np.cos(direcvrad)*dfWD['vwind'].values]\n",
    "# else:\n",
    "#     vecVel = [-np.sin(dfWD['wdir'].values * np.pi / 180) * dfWD['vwind'].values,\n",
    "#               np.cos(dfWD['wdir'].values * np.pi / 180)* dfWD['vwind'].values]\n",
    "#\n",
    "#\n",
    "# vecVelnp = np.array(vecVel).transpose()\n",
    "# #original sin timestamp\n",
    "# #df_comp_vel = pd.DataFrame(data=vecVelnp,columns=['vx','vy']\n",
    "# #con timestamp\n",
    "# df_comp_vel = pd.DataFrame(data=vecVelnp,columns=['vx','vy'],index=dfWD.index)\n",
    "#\n",
    "#\n",
    "# os.write(1, b\"Fin del procesamiento de datos\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inciando procesamiento de datos...\n",
      "\n",
      "Total de registros: 52560\n",
      "Numero de filas sin datos\n",
      "day      0.0\n",
      "hour     0.0\n",
      "wdir     0.0\n",
      "vwind    0.0\n",
      "dtype: float64\n",
      "Fin del procesamiento de datos\n"
     ]
    }
   ],
   "source": [
    "data_path ='datos/DP-PB01-2005.xlsx'\n",
    "mf_pow_curve_path ='datos/DeWind d8.2.csv'\n",
    "df_wind_dir, df_comp_vel,df_mf_curve = myfunc.proc_dat_bcs(data_path,mf_pow_curve_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matriz de transicion de viento"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_clusters= 15\n",
    "model_kmeans = KMeans( n_clusters=n_clusters,random_state=0)\n",
    "model_kmeans.fit(df_comp_vel.values)\n",
    "kmeans_labels = model_kmeans.labels_\n",
    "centroids = model_kmeans.cluster_centers_#los centroides siguen siendo 46\n",
    "n_clusters = np.unique(kmeans_labels).size\n",
    "\n",
    "#crear un dataframe viento, direccion, cluster\n",
    "df_wind_dir_cl = df_wind_dir.copy()\n",
    "df_wind_dir_cl['cluster'] = kmeans_labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordenar clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "                        C1     C2  C3     C4  C5  C6  C7  C8  C9  C10  C11  \\\n2005-01-01 00:10:00    NaN  1.898 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:20:00    NaN  1.759 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:30:00  0.893    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:40:00  1.016    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:50:00  1.092    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n...                    ...    ...  ..    ...  ..  ..  ..  ..  ..  ...  ...   \n2005-12-31 23:10:00    NaN  1.535 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:20:00    NaN    NaN NaN  2.085 NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:30:00  1.072    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:40:00  1.254    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:50:00  0.531    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n\n                     C12  C13  C14  C15  \n2005-01-01 00:10:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:20:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:30:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:40:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:50:00  NaN  NaN  NaN  NaN  \n...                  ...  ...  ...  ...  \n2005-12-31 23:10:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:20:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:30:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:40:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:50:00  NaN  NaN  NaN  NaN  \n\n[52559 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>C11</th>\n      <th>C12</th>\n      <th>C13</th>\n      <th>C14</th>\n      <th>C15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005-01-01 00:10:00</th>\n      <td>NaN</td>\n      <td>1.898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:20:00</th>\n      <td>NaN</td>\n      <td>1.759</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:30:00</th>\n      <td>0.893</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:40:00</th>\n      <td>1.016</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:50:00</th>\n      <td>1.092</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:10:00</th>\n      <td>NaN</td>\n      <td>1.535</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:20:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.085</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:30:00</th>\n      <td>1.072</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:40:00</th>\n      <td>1.254</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:50:00</th>\n      <td>0.531</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>52559 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#orden de aparicion de los clusters kmeans\n",
    "#ordenar el orden de aparicion segun la magnitud de la vv\n",
    "clmagni = np.zeros(n_clusters)\n",
    "for i in range(n_clusters):\n",
    "    vx = df_comp_vel.vx.values[kmeans_labels==i]\n",
    "    vy = df_comp_vel.vy.values[kmeans_labels==i]\n",
    "    clmagni[i]= np.round(np.mean(np.sqrt(vx**2 + vy**2)),1) #magnitud de la vv\n",
    "\n",
    "clord = clmagni.argsort()\n",
    "\n",
    "columnas=[]\n",
    "for i in np.arange(1,n_clusters+1):\n",
    "    columnas.append('C'+str(i))\n",
    "\n",
    "dfclvv = pd.DataFrame()\n",
    "for i in range(n_clusters):\n",
    "    dfclvv = pd.concat([dfclvv,df_wind_dir.vwind[kmeans_labels==clord[i]]], ignore_index=True, axis=1)\n",
    "dfclvv.columns=columnas[0:n_clusters]\n",
    "dfclvv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([24.53433284,  9.57209993,  6.78095093,  4.0430754 ,  9.17825682,\n        2.57805514,  0.88091478,  9.08312563,  3.23446032,  6.44799178,\n        3.45516467,  8.69499039,  3.4171122 ,  6.09790902,  2.00156015])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probabilidades de cada estado\n",
    "nregcl=[]\n",
    "for col in dfclvv.columns:\n",
    "    nregcl.append(len(dfclvv[dfclvv[col].notna()]))\n",
    "ntotreg= len(df_wind_dir)\n",
    "np.array(nregcl)/ntotreg *100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.4660483132997308\n",
      "1 - 2.1559827072152613\n",
      "2 - 2.49878591470258\n",
      "3 - 3.038021647058822\n",
      "4 - 4.316563432835808\n",
      "5 - 4.434022878228792\n",
      "6 - 6.206784017278621\n",
      "7 - 6.388041684122334\n",
      "8 - 6.993161764705888\n",
      "9 - 7.607657125995859\n",
      "10 - 7.65985737885462\n",
      "11 - 8.933557986870937\n",
      "12 - 10.341091314031186\n",
      "13 - 11.167419656786265\n",
      "14 - 11.255332699619768\n"
     ]
    }
   ],
   "source": [
    "#magnitud de los centroides\n",
    "for i in range(n_clusters):\n",
    "    print( str(i)+' - '+ str(dfclvv['C'+str(i+1)].mean()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2\n",
      "8.9\n",
      "3.0\n",
      "4.3\n",
      "10.3\n",
      "7.0\n",
      "6.4\n",
      "0.5\n",
      "11.2\n",
      "4.4\n",
      "11.3\n",
      "7.6\n",
      "7.7\n",
      "6.2\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "#resultado dudoso\n",
    "for i in range(n_clusters):\n",
    "    vx = df_comp_vel.vx.values[kmeans_labels==i]\n",
    "    vy = df_comp_vel.vy.values[kmeans_labels==i]\n",
    "    print(np.round(np.mean(np.sqrt(vx**2 + vy**2)),1) )#magnitud de la vv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matriz de velocidades de viento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Matriz sin ordenar\n",
    "columnas=[]\n",
    "for i in np.arange(1,n_clusters+1):\n",
    "    columnas.append('C'+str(i))\n",
    "\n",
    "\n",
    "dfclvv_sin_ord = pd.DataFrame()\n",
    "dfclvv_sin_ord.index= df_wind_dir.index\n",
    "for i in range(n_clusters):\n",
    "    dfclvv_sin_ord = pd.concat([dfclvv_sin_ord,df_wind_dir.vwind[kmeans_labels==i]], ignore_index=True, axis=1)\n",
    "dfclvv_sin_ord.columns=columnas[0:n_clusters]\n",
    "\n",
    "\n",
    "#ordenar\n",
    "#solo voy a cambiar el orden de las etiquetas\n",
    "#ordenando etiquetas por valores de centroides de mayor a menor\n",
    "columnas_ord=[x for _, x in sorted(zip(clord, columnas))]\n",
    "dfclvv_ord = dfclvv_sin_ord.copy()\n",
    "dfclvv_ord.columns = columnas_ord\n",
    "#ordenando nombres de columnas\n",
    "dfclvv_ord =dfclvv_ord[columnas]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                        C1     C2  C3     C4  C5  C6  C7  C8  C9  C10  C11  \\\ntimeStamp                                                                    \n2005-01-01 00:10:00    NaN  1.898 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:20:00    NaN  1.759 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:30:00  0.893    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:40:00  1.016    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-01-01 00:50:00  1.092    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n...                    ...    ...  ..    ...  ..  ..  ..  ..  ..  ...  ...   \n2005-12-31 23:10:00    NaN  1.535 NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:20:00    NaN    NaN NaN  2.085 NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:30:00  1.072    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:40:00  1.254    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n2005-12-31 23:50:00  0.531    NaN NaN    NaN NaN NaN NaN NaN NaN  NaN  NaN   \n\n                     C12  C13  C14  C15  \ntimeStamp                                \n2005-01-01 00:10:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:20:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:30:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:40:00  NaN  NaN  NaN  NaN  \n2005-01-01 00:50:00  NaN  NaN  NaN  NaN  \n...                  ...  ...  ...  ...  \n2005-12-31 23:10:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:20:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:30:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:40:00  NaN  NaN  NaN  NaN  \n2005-12-31 23:50:00  NaN  NaN  NaN  NaN  \n\n[52559 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>C11</th>\n      <th>C12</th>\n      <th>C13</th>\n      <th>C14</th>\n      <th>C15</th>\n    </tr>\n    <tr>\n      <th>timeStamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005-01-01 00:10:00</th>\n      <td>NaN</td>\n      <td>1.898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:20:00</th>\n      <td>NaN</td>\n      <td>1.759</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:30:00</th>\n      <td>0.893</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:40:00</th>\n      <td>1.016</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:50:00</th>\n      <td>1.092</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:10:00</th>\n      <td>NaN</td>\n      <td>1.535</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:20:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.085</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:30:00</th>\n      <td>1.072</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:40:00</th>\n      <td>1.254</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2005-12-31 23:50:00</th>\n      <td>0.531</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>52559 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclvv_ord"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cambiar de valor de velocidad de viento a unos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "#si quiero cambiar los NaN por ceros, pero hay algunos ceros en los datos\n",
    "# mejor dejo los NaN\n",
    "#dfclvv_sin_ord.fillna(0,inplace=True)\n",
    "#dfclvv_sin_ord[dfclvv_sin_ord!=0]=1\n",
    "#dfclvv_sin_ord.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#convetir matriz de estados a vector de estados (o transiciones)\n",
    "#este vector debe ser igual a kmeans_labels  cuando no se ha modificado el df\n",
    "vect_states = myfunc.mat_to_vector(dfclvv_sin_ord)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = df_wind_dir.loc[df_wind_dir.index.month ==1]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.step(data.index,model_kmeans.labels_[:len(data)],where='post')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "suma = []\n",
    "for i in range(n_clusters):\n",
    "    suma.append(len(dfclvv_ord[dfclvv_ord['C' + str(i+ 1)].notnull()]['C'+str(i+1)]) /len(dfclvv_sin_ord))\n",
    "    print(str(i) + '-'+str(suma[i]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matriz de transicion\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# m = transition_matrix(a)\n",
    "# m= np.multiply(m,100)\n",
    "# for row in m: print(' '.join('{0:.4f}'.format(x) for x in row))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #SOLO FUNCIONA PARA FILAS PERO NO PARA COLUMNAS\n",
    "# plt.figure(figsize=(20,18))\n",
    "#\n",
    "# ht =sns.heatmap(m, annot=True,fmt='.2f')\n",
    "# figure = ht.get_figure()\n",
    "# figure.savefig('ht_prob_internet.png', dpi=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(len(centroids)):\n",
    "#     # print(str(i) + ' - ' +str(np.sqrt(centroids[i][0]**2 + centroids[i][1]**2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "mat_trans_prob= myfunc.trans_matrix_from_df(dfclvv_ord,mat_mode='prob')\n",
    "mat_trans_prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#SOLO FUNCIONA PARA FILAS PERO NO PARA COLUMNAS\n",
    "plt.figure(figsize=(20,18))\n",
    "\n",
    "ht =sns.heatmap(mat_trans_prob, annot=True,fmt='.2f')\n",
    "figure = ht.get_figure()\n",
    "plt.show()\n",
    "figure.savefig('ht_prob_mio.png', dpi=400)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cadena de Markov"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Todos los estados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Plot de direcciones de viento\n",
    "################################################\n",
    "\n",
    "#valores menor a 10%\n",
    "#c = mat_trans_prob.mask(mat_trans_prob<10)\n",
    "\n",
    "#c.fillna(0,inplace=True)\n",
    "#c = np.round(c,4)\n",
    "#c = c[['C8','C12','C1ddd4','C15']]\n",
    "#revisar por que el .copy() es necesario, si no lo pongo afecta a la variable original\n",
    "myfunc.create_mc_plot(20,mat_trans_prob.copy(), as_pct=True, replace_zero_to_nan=False);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estados con probabilidad mayor a 10%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#elinminar valores menores a 10%\n",
    "matprob10p = mat_trans_prob.mask(mat_trans_prob<10)\n",
    "#conviertiendo nan a cero\n",
    "#matprob10p.fillna(0,inplace=True)\n",
    "#matprob10p = np.round(matprob10p,4)\n",
    "\n",
    "myfunc.create_mc_plot(21,matprob10p.copy(), as_pct=True, replace_zero_to_nan=True, layout='circle');\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combinar clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "clusters_wind = myfunc.KMData()\n",
    "clusters_wind.dataframe_to_cluster(df_comp_vel, n_clusters=n_clusters, clusters_data='wind')\n",
    "#crear un dataframe viento, direccion, cluster\n",
    "df_wind_dir_cl = df_wind_dir.copy()\n",
    "#tomando las labels de kmeans y sumandole uno por que empieza en 0\n",
    "#ademas agregando la letra C y ordenando de menor v a mayor vel\n",
    "col_clnames = ['C' + str(clusters_wind.cl_ord[c]+1) for c in clusters_wind.kmeans_labels]\n",
    "df_wind_dir_cl['cluster'] = col_clnames\n",
    "del col_clnames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Magnitud de viento"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#agrupando los datos de viento en clusters\n",
    "dfclvv = myfunc.create_clustered_data(df_wind_dir,clusters_wind.kmeans_labels)\n",
    "dfclvv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#combinando y eliminado clusters\n",
    "col_to_join = [['C1','C2','C3','C4','C5','C6',],['C8','C9'],['C10','C11'],['C12','C13'],['C14','C15']]\n",
    "col_to_del = [['C7']]\n",
    "dfclvv_joined = myfunc.join_clusters(dfclvv.copy(),col_to_join,col_to_del)\n",
    "dfclvv_joined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Markov"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#########################################################\n",
    "mat_trans_prob_joined= myfunc.trans_matrix_from_df(dfclvv_joined,mat_mode='prob')\n",
    "\n",
    "#SOLO FUNCIONA PARA FILAS PERO NO PARA COLUMNAS\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ht =sns.heatmap(mat_trans_prob_joined, annot=True,fmt='.2f')\n",
    "plt.show()\n",
    "figure = ht.get_figure()\n",
    "\n",
    "figure.savefig('ht_prob_joined.png', dpi=400)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "myfunc.create_mc_plot(100,mat_trans_prob_joined.copy(), filename='graph_mc_joined.jpg', as_pct=False,\n",
    "                      replace_zero_to_nan=False);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Componentes de veocidad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clusters unidos manualmente"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# col_to_join =['C1','C2','C3','C4','C5','C6',]\n",
    "# df_comp_vel_joined = join_clusters(clusters_wind.comp_vel,col_to_join)\n",
    "# col_to_join =['C8','C9']\n",
    "# df_comp_vel_joined = join_clusters(df_comp_vel_joined,col_to_join)\n",
    "# col_to_join =['C10','C11']\n",
    "# df_comp_vel_joined =  join_clusters(df_comp_vel_joined,col_to_join)\n",
    "# col_to_join =['C12','C13']\n",
    "# df_comp_vel_joined = join_clusters(df_comp_vel_joined,col_to_join)\n",
    "# col_to_join =['C14','C15']\n",
    "# df_comp_vel_joined = join_clusters(df_comp_vel_joined,col_to_join)\n",
    "# df_comp_vel_joined.drop('C7',axis=1,level=0,inplace=True)\n",
    "# #si no hago esto no se quita el C7 del indice y ocurre un error al querer plotear C7 que no existe\n",
    "# df_comp_vel_joined.columns =df_comp_vel_joined.columns.remove_unused_levels()\n",
    "col_to_join = [['C1','C2','C3','C4','C5','C6',],['C8','C9'],['C10','C11'],['C12','C13'],['C14','C15']]\n",
    "col_to_del = [['C7']]\n",
    "dfclvv_joined = myfunc.join_clusters(dfclvv.copy(),col_to_join,col_to_del)\n",
    "\n",
    "df_comp_vel_joined = myfunc.join_clusters(clusters_wind.comp_vel.copy(),col_to_join,col_to_del)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfclvv_joined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusters_wind.comp_vel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#calcular los nuevos centroides\n",
    "cent_teoricos=[]\n",
    "#si uso numpy o solo get level values ordena los clusters\n",
    "for cl in pd.unique(df_comp_vel_joined.columns.get_level_values(0)):\n",
    "    cent_teoricos.append(df_comp_vel_joined[cl].mean().values)\n",
    "#buscar centroides en los puntos existentes en los datos\n",
    "idx = []\n",
    "#agrupa los datos vx y vy y los suma, lo que resulta en solo dos columnas vx y vy\n",
    "vx_vy_group = df_comp_vel_joined.groupby(axis=1,level=1).sum()\n",
    "for cent in cent_teoricos:\n",
    "    idx.append( np.nanargmin(nan_euclidean_distances(vx_vy_group,[cent])))\n",
    "\n",
    "\n",
    "# buscar los valores vx,vy y timeStamp de los centroides en puntos reales\n",
    "lcent = []\n",
    "lcent_cl = []\n",
    "for i in idx:\n",
    "    lcent.append(vx_vy_group.iloc[i])\n",
    "    #añadir el cluster al que pertenece el centroide\n",
    "    lcent_cl.append(df_comp_vel_joined.iloc[i].dropna().index[0][0])\n",
    "#crear dataframe idx_centroids\n",
    "idx_centroids = pd.DataFrame(lcent)\n",
    "idx_centroids['ord_nat'] = lcent_cl\n",
    "idx_centroids.index.name = 'PCTimeStamp'\n",
    "idx_centroids\n",
    "#ordenar clusters por magnitud de viento\n",
    "mag_vv = []\n",
    "for row in lcent:\n",
    "    mag_vv.append(np.sqrt(row['vx']**2 + row['vy']**2))\n",
    "#son solo numeros de los indices\n",
    "orden_menmay=np.argsort(mag_vv)\n",
    "#son los nombres de los clusters obtenidos del dataframe\n",
    "#nuevo_orden=  list(df_comp_vel_joined.columns.levels[0])[orden_menmay]\n",
    "#actualizando orden de las columnas\n",
    "#df_comp_vel_joined.columns =pd.MultiIndex.from_product([nuevo_orden,['vx','vy']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calcular los nuevos centroides\n",
    "#cent_teoricos=[]\n",
    "idx = []\n",
    "#si uso numpy o solo get level values ordena los clusters\n",
    "for cl in pd.unique(df_comp_vel_joined.columns.get_level_values(0)):\n",
    "    cent_teorico = df_comp_vel_joined[cl].mean().values\n",
    "    idx.append( np.nanargmin(nan_euclidean_distances(\n",
    "        df_comp_vel_joined[cl],[cent_teorico])))\n",
    "\n",
    "#buscar centroides en los puntos existentes en los datos\n",
    "\n",
    "#agrupa los datos vx y vy y los suma, lo que resulta en solo dos columnas vx y vy\n",
    "# vx_vy_group = df_comp_vel_joined.groupby(axis=1,level=1).sum()\n",
    "# for cent in cent_teoricos:\n",
    "#     idx.append( np.nanargmin(nan_euclidean_distances(vx_vy_group,[cent])))\n",
    "\n",
    "\n",
    "# buscar los valores vx,vy y timeStamp de los centroides en puntos reales\n",
    "lcent = []\n",
    "lcent_cl = []\n",
    "for i in idx:\n",
    "    lcent.append(vx_vy_group.iloc[i])\n",
    "    #añadir el cluster al que pertenece el centroide\n",
    "    lcent_cl.append(df_comp_vel_joined.iloc[i].dropna().index[0][0])\n",
    "#crear dataframe idx_centroids\n",
    "idx_centroids = pd.DataFrame(lcent)\n",
    "idx_centroids['ord_nat'] = lcent_cl\n",
    "idx_centroids.index.name = 'PCTimeStamp'\n",
    "idx_centroids\n",
    "#ordenar clusters por magnitud de viento\n",
    "mag_vv = []\n",
    "for row in lcent:\n",
    "    mag_vv.append(np.sqrt(row['vx']**2 + row['vy']**2))\n",
    "#son solo numeros de los indices\n",
    "orden_menmay=np.argsort(mag_vv)\n",
    "#son los nombres de los clusters obtenidos del dataframe\n",
    "#nuevo_orden=  list(df_comp_vel_joined.columns.levels[0])[orden_menmay]\n",
    "#actualizando orden de las columnas\n",
    "#df_comp_vel_joined.columns =pd.MultiIndex.from_product([nuevo_orden,['vx','vy']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################\n",
    "clsclord=('wind',None)\n",
    "ploti = myfunc.PlotSubClusterInt()\n",
    "ploti.create_plot(\n",
    "    df_comp_vel_joined,\n",
    "    figsize=(20, 10),\n",
    "    idx_centroids=clusters_wind.idx_centroids.iloc[[0,7,9,11,13]],\n",
    "    fign='Figure '+ str(plt.gcf().number+1),\n",
    "    save_folder='figures_tests/',\n",
    "    filename = 'plot_clusters_joined',\n",
    "    showlBetz=False,\n",
    "    showCent= True,\n",
    "    showOpt= 'Numero',\n",
    "    dfMfgCurve=df_mf_curve\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5 clusters automaticos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "clusters_wind_5 = myfunc.KMData()\n",
    "clusters_wind_5.dataframe_to_cluster(df_comp_vel, n_clusters=n_clusters, clusters_data='wind')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "clsclord=('wind',None)\n",
    "ploti_5c = myfunc.PlotSubClusterInt()\n",
    "ploti_5c.create_plot(\n",
    "    clusters_wind_5.comp_vel,\n",
    "    figsize=(20, 10),\n",
    "    idx_centroids=clusters_wind_5.idx_centroids,\n",
    "    fign='Figure '+ str(plt.gcf().number+1),\n",
    "    save_folder = 'figures_tests/',\n",
    "    filename = 'plot5clusters',\n",
    "    showlBetz=False,\n",
    "    showCent= True,\n",
    "    showOpt= 'Numero',\n",
    "    dfMfgCurve=df_mf_curve\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tiempo total que pasa en estados de interes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#direcciones promedio\n",
    "for col in dfclvv_sin_ord.columns:\n",
    "    print(col+ ' - ' +str(df_wind_dir.wdir[dfclvv_sin_ord[col] !=0 ].mean()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#obtener estados entre dos velocidades de viento\n",
    "#primero obtengo las velocidades de viento y de ahi los estados\n",
    "#por ejemplo seleccionar los estados que ocurren entre las velocidades 6 y 11\n",
    "#y ver como brincan entre estados y cuanto duran estas transiciones antes\n",
    "# de que brinquen a estados que no son de interes\n",
    "betw = df_wind_dir[df_wind_dir.vwind.between(6,11)]\n",
    "betw.index = pd.to_datetime(pd.to_datetime(betw.index).strftime('%d/%m/%Y %H:%M'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfclvv_sin_ord.index = pd.to_datetime(pd.to_datetime(dfclvv_sin_ord.index).strftime('%d/%m/%Y %H:%M'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#buscar cuanto duran los estados\n",
    "#fila por fila\n",
    "#contador de tiempos de 10 minutos para tener lo hora total\n",
    "t10_count = 10\n",
    "#lista con todos los tiempos totales\n",
    "list_total_times=[]\n",
    "\n",
    "df = betw\n",
    "for row in range(len(df)-1):\n",
    "    #obtener el estado de del registro\n",
    "    estado = dfclvv_sin_ord.loc[df.index[row]].to_numpy().reshape(-1).nonzero()[0][0]+1\n",
    "    #comprobar que la diferencia entre una fila y la siguiente es de diez minutos\n",
    "    if df.index[row+1] - df.index[row]  == pd.Timedelta(minutes=10):\n",
    "        # dato de la fila\n",
    "        t10_count+=10 #sumar 10 minutos\n",
    "        register = df.iloc[row]\n",
    "        print('%s | %0.2f m/s | %0.1f°| C%i'%\n",
    "              (register.name,register.vwind,register.wdir, estado))\n",
    "    else:\n",
    "        register = df.iloc[row]\n",
    "        print('%s | %0.2f m/s | %0.1f°| C%i'%\n",
    "              (register.name,register.vwind,register.wdir,estado))\n",
    "        list_total_times.append(pd.to_datetime(t10_count,unit='m').strftime('%H:%M'))\n",
    "        print('Total time: %s hr(s)' % list_total_times[-1] )\n",
    "        print('########################################')\n",
    "        t10_count = 10\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#buscar cuanto duran los estados\n",
    "#fila por fila\n",
    "#contador de tiempos de 10 minutos para tener lo hora total\n",
    "t10_count = 10\n",
    "#lista con todos los tiempos totales\n",
    "list_total_times=[]\n",
    "\n",
    "df = df_wind_dir\n",
    "#indica a que grupo pertenece el dato\n",
    "#con el codigo de abajo, los estados se dividen en grupos\n",
    "#pero cronologicamente, para luego identificar a que grupo\n",
    "#pertenece cierto registro le añado un indice\n",
    "#por lo que se tienen datos agrupados por clusters de magnitudes de voltaje\n",
    "#y por clusters de tiempos consecutivos de ocurrencia\n",
    "grouped_states_index = 1\n",
    "\n",
    "for row in range(len(df)):\n",
    "    #obtener el estado de del registro\n",
    "    #reshape porque a veces me da un array de 1xn y a veces de nx1\n",
    "    estado_ini = dfclvv_sin_ord.loc[df.index[row]].to_numpy().reshape(-1).nonzero()[0][0]+1\n",
    "    estado_sig = dfclvv_sin_ord.loc[df.index[row+1]].to_numpy().reshape(-1).nonzero()[0][0]+1\n",
    "    #comprobar que la diferencia entre una fila y la siguiente es de diez minutos\n",
    "    if estado_ini == estado_sig:\n",
    "        # dato de la fila\n",
    "        t10_count+=10 #sumar 10 minutos\n",
    "        register = df.iloc[row]\n",
    "        print('%s | %0.2f m/s | %0.1f°| C%i |gp_idx: %i |'%\n",
    "              (register.name,register.vwind,register.wdir, estado_sig,grouped_states_index))\n",
    "    else:\n",
    "        register = df.iloc[row]\n",
    "        print('%s | %0.2f m/s | %0.1f°| C%i |gp_idx: %i |'%\n",
    "              (register.name,register.vwind,register.wdir,estado_ini,grouped_states_index))\n",
    "        list_total_times.append(pd.to_datetime(t10_count,unit='m').strftime('%H:%M'))\n",
    "        print('Total time: %s hr(s)' % list_total_times[-1] )\n",
    "        print('########################################')\n",
    "        t10_count = 10\n",
    "        grouped_states_index+=1 #nuevo grupo, nuevo indice\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_wind_dir_cl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "row = 0\n",
    "dfclvv_sin_ord.loc[df.index[row]].to_numpy().reshape(-1).nonzero()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(dfclvv_sin_ord.loc[df.index[row]].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfclvv_sin_ord"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#este dataframe contendrá en orden cronologíco los datos con una fila extra indicando\n",
    "#el cluster al que pertenece el dato. Se puede hacer manual o pandificado\n",
    "#aqui lo voy a hacer pandificado\n",
    "df_data_with_states = df_wind_dir.copy()\n",
    "dfclvv_sin_ord.loc['2005-01-01 00:50:00'].to_numpy().nonzero()[0][0]+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Buscar transiciones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vel_prom_estados = [8.2,10.7, 12.4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1.- encontrar el primer dato no NAN del estado (df ordenado cronologicamente)\n",
    "# 2.- encontrar el siguiente dato NAN. El estado se encuentra entre estos dos no NAN y NAN\n",
    "#\n",
    "\n",
    "dfclvv_sin_ord.C1.first_valid_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfclvv_sin_ord.C1.isnull()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #va a buscar renglon por renglon si el valor es nan y\n",
    "# #va a agrupar los valores que no son nan junto con su timestamp\n",
    "# num_estado = 'C17'\n",
    "# dfclvv_sin_ord[num_estado].first_valid_index() #primer valor que no es nan\n",
    "# lista=[]\n",
    "# C=[]\n",
    "# flag= True\n",
    "# for i in dfclvv_sin_ord[num_estado].itertuples():\n",
    "#     if not np.isnan(i[1]):\n",
    "#         C.append([i[0],i.vViento,i.Pw])\n",
    "#         flag = False\n",
    "#\n",
    "#\n",
    "#     if not flag:\n",
    "#         lista.append(C)\n",
    "#         C.clear()\n",
    "#         flag_nonan=True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# c17agrupado = group_state_values(17,dfclvv_sin_ord)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# listaTiempos=[] #cuenta el numero de elementos que tiene cada lista\n",
    "# #es decir si la lista contiene 4 elementos, quiere decir que el estado\n",
    "# #estuvo sin cambios 40 minutos\n",
    "# for i in c17agrupado:\n",
    "#     listaTiempos.append(len(i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #moda de los tiempos por cada unidad son 10 minutos\n",
    "# stats.mode( listaTiempos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #promedio de los tiempos de estadia, 1.95 es aprox 2 o 20 min\n",
    "# np.mean(listaTiempos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tempdf= dfclvv_sin_ord.C17.copy()\n",
    "# tempdf.dropna(inplace=True)\n",
    "# tempdf.reset_index(inplace=True)\n",
    "# tempdf.rename(columns={'index':'timeStamp'},inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #solo conservar las horas\n",
    "# l=tempdf['timeStamp'].dt.time.values\n",
    "# #calcular la moda, es decir, a que hora es más probable el estado\n",
    "# stats.mode(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Markov chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#falta ordenar los nombres de columnas\n",
    "col_to_join =['C1','C2','C3','C4','C5','C6',]\n",
    "b = clusters_wind.comp_vel\n",
    "\n",
    "c = b[col_to_join].groupby(level=1,axis=1).sum(min_count=1)\n",
    "c.columns = pd.MultiIndex.from_product([['C_'],['vx','vy']])\n",
    "b = b.join(c)\n",
    "b.drop(col_to_join,level=0,axis=1,inplace=True)\n",
    "b.rename({'C_':col_to_join[0]},axis=1,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "pycharm-a777efb8",
   "language": "python",
   "display_name": "PyCharm (aero)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}