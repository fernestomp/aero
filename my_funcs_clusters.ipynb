{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook de funciones que usan los demás notebooks. Este debe contener las fuciones actualizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "def raw_to_datafr (xlsPath, xlsPathMfgCurve):\n",
    "    \"\"\"\n",
    "\n",
    "    :param xlsPath: path to data file\n",
    "    :param xlsPathMfgCurve: path to manufacturer power curve file\n",
    "    :return: processed dataframes\n",
    "    \"\"\"\n",
    "    #imprimir a consola\n",
    "    os.write(1, b\"Inciando procesamiento de datos...\\n\")\n",
    "\n",
    "    \n",
    "    #xlsPath = 'C:/Users/mungu/Documents/DatosWTG.xlsx'\n",
    "    #xlsPath = 'C:\\\\Users\\\\ernesto\\\\Dropbox\\\\Doctorado\\\\datos\\\\DatosWTG.xlsx'\n",
    "    #xlsPathMfgCurve = 'Curva de potencia vestas 90.xlsx'\n",
    "\n",
    "    #dataVPxls = pd.read_excel(xlsPath,usecols=[0,1,2],index_col=0,names=['vViento','Pacw'])\n",
    "    dataVPxls = pd.read_excel(xlsPath,usecols=[0,1,2],index_col=0)\n",
    "    dataVPxls.columns =['vViento','Pacw']\n",
    "    #agrego la columna de potencia instantanea sin filtrar\n",
    "    #dataVPxls['Pw']= (dataVPxls.iloc[1:,1].values-dataVPxls.iloc[0:-1,1]) * np.pi*45**2\n",
    "    print('Total de registros: ' + str(len(dataVPxls)))\n",
    "    #dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0,names=['pw'])#cambio esto en la nueva version\n",
    "    dfMfgCurve = pd.read_excel(xlsPathMfgCurve,usecols=[0,2],index_col=0)\n",
    "    dfMfgCurve.columns = ['pw']\n",
    "    #marcando los datos faltantes asignando un nan a la fila completa\n",
    "    datamk = dataVPxls\n",
    "    datamk.loc[datamk.isnull().any(axis=1), :] = np.nan\n",
    "    #numero de filas sin datos\n",
    "    print('Numero de filas sin datos')\n",
    "    print(datamk.loc[datamk.isnull().any(axis=1), :].isnull().sum())\n",
    "\n",
    "    #eliminando filas con NaN. Si busco la fecha anterior debe aparecer error.\n",
    "    cleanData = datamk.dropna()\n",
    "\n",
    "    ###calculando la potencia\n",
    "    #la pontencia del archivo de excel es la densidad de potencia acumulada.\n",
    "    #Se tiene que hacer la resta de la potencia siguiente a la anterio y multiplicar por pi*r^2\n",
    "    #el radio es 45m\n",
    "    #si se hace la resta con un array de numpy (values) si se puede restar \n",
    "    #pues se hace elemento por elemento\n",
    "    dataVP = cleanData.drop('Pacw',axis=1)\n",
    "    dataVP['Pw']= (cleanData.iloc[1:,1].values-cleanData.iloc[0:-1,1]) * np.pi*45**2\n",
    "\n",
    "    #eliminar el ultimo valor pues es NaN\n",
    "    dataVP.drop(dataVP.tail(1).index,inplace=True) \n",
    "\n",
    "    #Eliminando outliers\n",
    "    dataVP.drop([pd.to_datetime('2016-03-07 09:50:00')],inplace=True)\n",
    "    #agregado para el reporte\n",
    "    dataVP.drop([pd.to_datetime('2016-03-08 09:00:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-01-02 06:40:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-05-05 07:20:00')],inplace=True)\n",
    "    dataVP.drop([pd.to_datetime('2016-05-23 23:00:00')],inplace=True)\n",
    "\n",
    "\n",
    "    #leyendo la direccion del viento\n",
    "    #dataDirVxls = pd.read_excel(xlsPath,sheet_name=1, usecols=[0,1],index_col=0,names=['Dir'])\n",
    "    dataDirVxls = pd.read_excel(xlsPath,sheet_name=1, usecols=[0,1],index_col=0)\n",
    "    dataDirVxls.columns =['Dir']\n",
    "    #limpiando datos\n",
    "    #marcando los datos faltantes asignando un nan a la fila completa\n",
    "    datamkdir = dataDirVxls\n",
    "    datamkdir.loc[datamkdir.isnull().any(axis=1), :] = np.nan\n",
    "    #eliminando filas con NaN. Si busco la fecha anterior debe aparecer error.\n",
    "    #tambien elimino el ultimo valor como lo hice en los datos de v y p\n",
    "    #el copy es para que no me de la copy warning\n",
    "    dataDir = datamkdir.dropna().copy()\n",
    "    dataDir.drop(dataDir.tail(1).index,inplace=True) \n",
    "    #eliminando del outlier de viento misma fecha que el de la pontencia\n",
    "    dataDir.drop([pd.to_datetime('2016-03-07 09:50:00')],inplace=True)\n",
    "    #agregado para el reporte\n",
    "    dataDir.drop([pd.to_datetime('2016-03-08 09:00:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-01-02 06:40:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-05-05 07:20:00')],inplace=True)\n",
    "    dataDir.drop([pd.to_datetime('2016-05-23 23:00:00')],inplace=True)\n",
    "\n",
    "    direcvrad= np.deg2rad(dataDir['Dir'].values)\n",
    "    velocidades = dataVP.iloc[:]['vViento'].values\n",
    "    vecVel = [-np.sin(direcvrad)*velocidades,np.cos(direcvrad)*velocidades]\n",
    "    vecVelnp=np.array(vecVel).transpose()\n",
    "    #original sin timestamp\n",
    "    #dfVecVel = pd.DataFrame(data=vecVelnp,columns=['vx','vy']\n",
    "    #con timestamp\n",
    "    dfVecVel = pd.DataFrame(data=vecVelnp,columns=['vx','vy'],index=dataVP.index)\n",
    "\n",
    "    #datos direccion velocidad\n",
    "    #print(len(dataVP))\n",
    "    #print(len(dataDir))\n",
    "    #dataDV = pd.concat([dataDir,dataVP.vViento],axis=1)\n",
    "    dataVDP = pd.concat([dataVP.vViento,dataDir,dataVP.Pw],axis=1)\n",
    "    #dataVcD =pd.concat([dataDir,dfVecVel],axis=1)\n",
    "    #Datos en p.u.. Divido todos los datos entre el máximo del conjunto de datos\n",
    "\n",
    "\n",
    "    #OPERATIONAL DATA\t\n",
    "    # Rated power\n",
    "    # 2,000 kW/2,200 kW\n",
    "    # Cut-in wind speed\t4 m/s\n",
    "    # Cut-out wind speed\t25 m/s\n",
    "    # Re cut-in wind speed\t23 m/s\n",
    "\n",
    "\n",
    "    os.write(1, b\"Fin del procesamiento de datos\\n\")\n",
    "    return [dataVDP,dfVecVel,dfMfgCurve]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear plot interactivo para cluster y subcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"'''\n",
    "TODO:\n",
    "    -que de una opción de mostrar solo viento o potencia aunque tenga subclusters\n",
    "    -que funcione si solo incluyo dfclvv aunque tenga subclusters\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RadioButtons, TextBox\n",
    "from IPython.display import display as wgdisplay\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import datetime\n",
    "from matplotlib.ticker import EngFormatter\n",
    "import matplotlib.patheffects as path_effects #efectos de texto\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "plt.style.use('seaborn-white')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "class PlotSubClusterInt:\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Clase para dibujar dos subplots, uno vx vs vy y otro vviento vs Pw.\n",
    "\n",
    "    Metodos:\n",
    "        createPlot: Construye el plot de matplotlib.\n",
    "            self.dfclvv: dataframe multiindice con dos columnas vx y vy agrupadas por cluster\n",
    "            dfclpw: dataframe multiindice con dos columnas vviento y Pw agrupadas por cluster\n",
    "            cl_method: string que almacena el metodo usado para hacer el cluster\n",
    "                     |   C1    |   C2   |...\n",
    "                    ----------------------\n",
    "            Timestamp|  vx vy  |  vx vy |...            datavp: dataframe original de los datos de\n",
    "\n",
    "        updatePlot: actuliza el plot en \"tiempo real\" segun los valores de los controles\n",
    "\n",
    "        onClick: Es el la funcion que esta ligada al click en el plot. Solo ejecuta annotatePlot.\n",
    "\n",
    "        annotatePlot: Crea una anotacion en el plot que indica donde el nombre del cluster mas cercano al conjunto de\n",
    "              coordenadas donde se hizo click en el plot VP. Ademas muestra el cluster en el plot VV.\n",
    "\n",
    "        blinkCluster: Resalta el cluster al que se hace referencia.\n",
    "\n",
    "    Argumentos:\n",
    "        cl_scl_order: el orden en que se hicieron los clusters (viento,viento), (viento,potencia),\n",
    "            (potencia,viento),(potencia,potencia)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.axvp = None\n",
    "        self.formatterPw = None\n",
    "        self.fig = None\n",
    "        self.axvv = None\n",
    "        self.tbFilePath = None\n",
    "        self.wchkcls = None\n",
    "        self.tbreta = None\n",
    "        self.wradText = None\n",
    "        self.chkShowCPotFab = None\n",
    "        self.chkShowBetz = None\n",
    "        self.chkLimGlob = None\n",
    "        self.chkShowCnt = None\n",
    "        self.wdgPSize = None\n",
    "        self.btnSelNoneChk = None\n",
    "        self.btnSelAllChk = None\n",
    "        self.btnUpdate = None\n",
    "        self.vxmaxGlob = None\n",
    "        self.pmaxGlob = None\n",
    "        self.vvmaxGlob = None\n",
    "        self.vvminGlob = None\n",
    "        self.pminGlob = None\n",
    "        self.vymaxGlob = None\n",
    "        self.vyminGlob = None\n",
    "        self.vxminGlob = None\n",
    "        self.cl_avail = None\n",
    "        self.clnames_all = None\n",
    "        self.n_tot_clusters = None\n",
    "        self.idx_centroids_sc = None\n",
    "        self.idx_centroids = None\n",
    "        self.dfclvp = None\n",
    "        self.n_clusters = None\n",
    "        self.showLegends = None\n",
    "        self.savepath = None\n",
    "        self.showlBetz = None\n",
    "        self.showCent = None\n",
    "        self.showMfgCurve = None\n",
    "        self.showOpts = None\n",
    "        self.vvento = None\n",
    "        self.PMaxViento = None\n",
    "        self.cl_scl_order = None\n",
    "        from colorsys import hls_to_rgb\n",
    "\n",
    "        self.fignum=999\n",
    "        self.fisize = (5, 5)\n",
    "        self.fontsize = 13\n",
    "        self.labelFontSize = 13\n",
    "        self.tickFontSize = 12\n",
    "        self.markerSize = 100\n",
    "        self.fontNameLabel = {'fontname':'Times New Roman'}\n",
    "        self.fontNameCluster = {'fontname':'Arial'}\n",
    "        self.ticks_font = font_manager.FontProperties(family='Times New Roman', style='normal',\n",
    "                                                      size=self.labelFontSize, weight='normal', stretch='normal')\n",
    "        self.n_subclu = 0\n",
    "        colors1 = plt.cm.tab20(np.linspace(0., 1, 20))\n",
    "        colors2 = plt.cm.Spectral(np.linspace(0, 1, 10))\n",
    "        colorstab = np.vstack((colors1, colors2))\n",
    "        self.mapa_colores=colorstab\n",
    "        self.fisize = None\n",
    "        self.dfclvv = None\n",
    "        self.datavp = None\n",
    "        self.dfMfgCurve=None\n",
    "        self.dfclvp_is_empty = True\n",
    "\n",
    "\n",
    "    def create_plot(self, dfclvv, dfclvp=None,datavp=None,figsize=(5, 5), cl_scl_order=(None, None),\n",
    "                    idx_centroids=None,idx_centroids_sc=None,fign=999, savepath='', showCent =True,\n",
    "                    showlBetz = True,showMfgCurve=True, showOpt = 'Magnitud',dfMfgCurve=None,\n",
    "                    showLegends = True):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dfclvv:\n",
    "        :param dfclvp:\n",
    "        :param datavp:\n",
    "        :param figsize:\n",
    "        :param cl_scl_order:\n",
    "        :param idx_centroids:\n",
    "        :param idx_centroids_sc:\n",
    "        :param fign:\n",
    "        :param savepath:\n",
    "        :param showCent:\n",
    "        :param showlBetz:\n",
    "        :param showMfgCurve:\n",
    "        :param showOpt:\n",
    "        :param dfMfgCurve:\n",
    "        :param showLegends:\n",
    "        \"\"\"\n",
    "        self.dfMfgCurve=dfMfgCurve\n",
    "        if self.dfMfgCurve is None:\n",
    "            os.write(1,b'Manufacturer power curve missing')\n",
    "        self.showLegends = showLegends\n",
    "        self.cl_scl_order = cl_scl_order\n",
    "        self.dfclvp =dfclvp\n",
    "        self.dfclvv = dfclvv\n",
    "        self.datavp = datavp\n",
    "        self.n_clusters = len(self.dfclvv.columns.levels[0])\n",
    "        self.n_tot_clusters =self.n_clusters\n",
    "        self.fignum =fign\n",
    "        self.idx_centroids =idx_centroids\n",
    "        self.idx_centroids_sc= idx_centroids_sc\n",
    "        self.savepath = savepath\n",
    "        self.showlBetz = showlBetz # show Betz's limit\n",
    "        self.showCent = showCent # show clusters centroids\n",
    "        self.showMfgCurve = showMfgCurve #show manufacturer's curve\n",
    "        #which value is shown in the plot magnitude,cluster number,cluster name, none\n",
    "        self.showOpts = showOpt\n",
    "\n",
    "        #check if power data was passed\n",
    "        if self.dfclvp is not None:\n",
    "            self.dfclvp_is_empty = False\n",
    "\n",
    "        ##################################\n",
    "        #        limite de betz          #\n",
    "        ##################################\n",
    "        if not self.dfclvp_is_empty:\n",
    "            A=np.pi*45**2\n",
    "            Cp = 0.59 #limite de Betz\n",
    "            rho = 1.1349\n",
    "            self.vvento = np.unique(datavp.vViento.values)\n",
    "            self.PMaxViento = 1/2*rho*A*self.vvento**3*Cp\n",
    "\n",
    "        #########################################\n",
    "        #           DATAFRAME ANALYSIS          #\n",
    "        #########################################\n",
    "\n",
    "\n",
    "\n",
    "        plt.ion()\n",
    "        self.fig = plt.figure(self.fignum, figsize=self.fisize)\n",
    "        self.axvv = self.fig.add_subplot(121)\n",
    "        #1k, 1M\n",
    "        self.formatterPw = EngFormatter(places=1, sep=\"\\N{THIN SPACE}\")  # U+2009\n",
    "        # 3 because is cluster,subcluster,vx and vy\n",
    "        if len(dfclvv.columns[0]) == 3:\n",
    "            #last column has the last subcluster name SCn, this gives n\n",
    "            self.n_subclu=int(dfclvv.columns[-1][1][2:])\n",
    "\n",
    "        if not self.dfclvp_is_empty:\n",
    "            if self.n_subclu > 0:  # existen subclusters , sino seria 2\n",
    "                #numero total de clusters incluidos los subclusters\n",
    "                self.n_tot_clusters = self.n_subclu*self.n_clusters\n",
    "                # solo aplica cuando hay subclusters\n",
    "                lev0 = self.dfclvv.columns.get_level_values(0)\n",
    "                lev1 = self.dfclvp.columns.get_level_values(1)\n",
    "                namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "                #self.clnames_all = sorted(namcl[::2]) #todos los clusters y subclusters disponibles\n",
    "                self.clnames_all = namcl[::2] #todos los clusters y subclusters disponibles\n",
    "                #ordenar\n",
    "                vv = [self.idx_centroids_sc.loc[c].vViento for c in self.clnames_all]\n",
    "                idx = np.argsort(vv)\n",
    "                x=[self.clnames_all[i] for i in idx]\n",
    "                self.clnames_all=x.copy()\n",
    "                del x\n",
    "                #nombre de los clusters disponibles sin el nombre de los subclusters\n",
    "                #self.cl_avail =sorted(set(item[0] for item in self.clnames_all))\n",
    "                self.cl_avail =set(item[0] for item in self.clnames_all)\n",
    "                #### BUSCAR MINIMOS Y MAXIMOS GLOBALES  (hacerlo más elegante)\n",
    "                l=[self.dfclvv[cl].min() for cl in self.clnames_all]\n",
    "                self.vxminGlob,self.vyminGlob =   np.amin(l,axis=0)\n",
    "                l=[self.dfclvv[cl].max() for cl in self.clnames_all]\n",
    "                self.vxmaxGlob,self.vymaxGlob =   np.amax(l,axis=0)\n",
    "\n",
    "            else:  # no hay subcluster\n",
    "                #lista ordenada con numeros y letras\n",
    "                self.clnames_all=sorted(dfclvv.columns.levels[0],\n",
    "                                        key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n",
    "                #self.cl_avail =sorted(set(item for item in self.clnames_all))\n",
    "                self.cl_avail =set(item for item in self.clnames_all)\n",
    "            l=[self.dfclvp[cl].min() for cl in self.clnames_all]\n",
    "            self.vvminGlob,self.pminGlob =   np.amin(l,axis=0)\n",
    "            l=[self.dfclvp[cl].max() for cl in self.clnames_all]\n",
    "            self.vvmaxGlob,self.pmaxGlob =   np.amax(l,axis=0)\n",
    "        else:\n",
    "            #lista ordenada con numeros y letras\n",
    "            self.clnames_all=sorted(dfclvv.columns.levels[0],\n",
    "                                    key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n",
    "            #self.cl_avail =sorted(set(item for item in self.clnames_all))\n",
    "            self.cl_avail =set(item for item in self.clnames_all)\n",
    "            #### BUSCAR MINIMOS Y MAXIMOS GLOBALES  (hacerlo más elegante)\n",
    "            l=[self.dfclvv[cl].min() for cl in self.clnames_all]\n",
    "            self.vxminGlob,self.vyminGlob =   np.amin(l,axis=0)\n",
    "            l=[self.dfclvv[cl].max() for cl in self.clnames_all]\n",
    "            self.vxmaxGlob,self.vymaxGlob =   np.amax(l,axis=0)\n",
    "\n",
    "        if not self.dfclvp_is_empty:\n",
    "            self.axvp = self.fig.add_subplot(122)\n",
    "            self.axvp.yaxis.set_major_formatter(self.formatterPw)\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################################\n",
    "        #                             WIDGETS                                        #\n",
    "        ##############################################################################\n",
    "\n",
    "        self.btnUpdate = widgets.Button(description='Actualizar')\n",
    "\n",
    "        self.btnUpdate.on_click(self.update_plot)\n",
    "        self.btnSelAllChk = widgets.Button(description='Sel. todo')\n",
    "        self.btnSelAllChk.on_click(self.sel_all_chk)\n",
    "        self.btnSelNoneChk = widgets.Button(description='Des. todo')\n",
    "        self.btnSelNoneChk.on_click(self.sel_none_chk)\n",
    "        self.wdgPSize = widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=1,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            description='Point size:',\n",
    "            continuous_update=False)\n",
    "        self.chkLimGlob = widgets.Checkbox(\n",
    "            value=True, description='Límites Globales')\n",
    "        self.chkShowCnt = widgets.Checkbox(\n",
    "            value=self.showCent, description='Mostrar centroides')\n",
    "        self.chkShowBetz = widgets.Checkbox(\n",
    "            value=self.showlBetz, description='Mostrar línea Betz')\n",
    "        self.chkShowCPotFab = widgets.Checkbox(\n",
    "            value=self.showMfgCurve, description='Mostrar curva Fab.')\n",
    "        if not self.dfclvp_is_empty:\n",
    "            if self.dfMfgCurve is not None:\n",
    "                self.chkShowCPotFab.disabled= False\n",
    "            else:\n",
    "                self.chkShowCPotFab.disabled= True\n",
    "        else:\n",
    "            self.chkShowBetz.disabled=True\n",
    "\n",
    "\n",
    "        self.tbreta = widgets.IntText(\n",
    "            value=0, description='Retardo:', layout=Layout(width='90%', height='80px'))\n",
    "        self.wradText = widgets.RadioButtons(\n",
    "            options=['Magnitud', 'Numero', 'Clusters', 'Ninguno'],\n",
    "            description='Mostrar texto:')\n",
    "        self.wradText.value= self.showOpts\n",
    "        figsavepath = self.savepath\n",
    "        figsavename = 'clustersplot'+str(self.n_clusters)+'SCl'+str(self.n_subclu)+'_'\n",
    "        figsavetime = datetime.datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S_%f\")\n",
    "        self.tbFilePath = widgets.Text(\n",
    "            value=figsavepath+figsavename+figsavetime+'.jpg',\n",
    "            description='Save path:', layout=Layout(width='90%', height='80px'))\n",
    "        #self.chkShowCnt.observe(self.updatePlot, 'value')\n",
    "        #self.wdgPSize.observe(self.updatePlot, 'value')\n",
    "        self.wradText.observe(self.update_plot, 'value')\n",
    "        #self.chkShowBetz.observe(self.updatePlot, 'value')\n",
    "        #self.chkShowCPotFab.observe(self.updatePlot, 'value')\n",
    "\n",
    "\n",
    "        self.wchkcls=[] #lista de checbox con los nombresde los clusters\n",
    "        n=1#para numerar la lista de clusters\n",
    "        for i in range(len(self.clnames_all)):\n",
    "            self.wchkcls.append(widgets.Checkbox(\n",
    "                value=True, description=str(n) +'-' +str(self.clnames_all[i])))\n",
    "            n+=1\n",
    "        box_layout = Layout(display='flex',\n",
    "                            flex_flow='column',\n",
    "                            align_items='stretch',\n",
    "                            height='200px',\n",
    "                            )\n",
    "        vbchkcls = widgets.VBox(self.wchkcls, layout=box_layout)\n",
    "\n",
    "        self.text_log=widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Log',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        # -------------   WIDGETS EN CAJAS ----------------------\n",
    "        vbopt1 = widgets.VBox([self.chkShowCnt,self.chkShowBetz, self.chkShowCPotFab,self.chkLimGlob, self.tbreta])\n",
    "        vbopt2 = widgets.VBox([self.wradText, self.wdgPSize ])\n",
    "        vbButtons = widgets.VBox([self.btnSelAllChk,self.btnSelNoneChk, self.btnUpdate, self.tbFilePath])\n",
    "        vblog = widgets.VBox([self.text_log])\n",
    "        items = [vbButtons, vbchkcls,vbopt1,vbopt2]\n",
    "        hb = widgets.HBox(items)\n",
    "        wgdisplay(hb)\n",
    "        wgdisplay(vblog)\n",
    "        #wgdisplay(self.fig)\n",
    "        #####################################\n",
    "        #               PLOTs               #\n",
    "        #####################################\n",
    "\n",
    "        self.update_plot(1)\n",
    "\n",
    "    def sel_all_chk(self,val):\n",
    "        \"\"\"\n",
    "\n",
    "        :param self:\n",
    "        :param val:\n",
    "        \"\"\"\n",
    "        for item in self.wchkcls:\n",
    "            item.value=True\n",
    "    def sel_none_chk(self,val):\n",
    "        \"\"\"\n",
    "\n",
    "        :param self:\n",
    "        :param val:\n",
    "        \"\"\"\n",
    "        for item in self.wchkcls:\n",
    "            item.value=False\n",
    "    def save_plot(self,val):\n",
    "        \"\"\"\n",
    "\n",
    "        :param self:\n",
    "        :param val:\n",
    "        \"\"\"\n",
    "        self.text_log.value ='Guardando plot...'\n",
    "        figsavepath = self.savepath\n",
    "        figsavename = 'VVVPCl'+str(self.n_clusters)+'SCl'+str(self.n_subclu)+'_'\n",
    "        #         figsavetime = datetime.datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S_%f\")\n",
    "        self.tbFilePath.value=figsavepath+figsavename+'.png'\n",
    "\n",
    "        plt.savefig(  self.tbFilePath.value, bbox_inches='tight', pad_inches=0.1)\n",
    "        #print('Saved in ' +  self.tbFilePath.value)\n",
    "        self.text_log.value ='Plot guardado en: ' + self.tbFilePath.value\n",
    "\n",
    "    def update_plot(self, val):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param val:\n",
    "        \"\"\"\n",
    "        self.text_log.value = 'Actualizando plot...'\n",
    "        pSize = self.wdgPSize.value\n",
    "        self.axvv.axes.clear()\n",
    "        self.axvv.grid(visible = True)\n",
    "        if not self.dfclvp_is_empty:\n",
    "            self.axvp.axes.clear()\n",
    "            self.axvp.grid()\n",
    "\n",
    "\n",
    "        if self.n_subclu>0 :  # existen subclusters\n",
    "\n",
    "            clnames= [eval(el.description.split('-')[1]) for el in self.wchkcls if el.value==True]\n",
    "            #ordenar subclusters por velocidad\n",
    "            #los subclusters se ordenan dentro de cada grupo de clusters en idx_centrods_sc\n",
    "            #hay que ordenarlos tambien globalmente y no solo localmente\n",
    "            #self.cl_avail =sorted(set(item[0] for item in clnames))\n",
    "            vv = [self.idx_centroids_sc.loc[c].vViento for c in clnames]\n",
    "            idx = np.argsort(vv)\n",
    "            x=[clnames[i] for i in idx]\n",
    "            clnames=x.copy()\n",
    "            del x\n",
    "            #self.clnames_all =clnames# REV: SE OCUPA CLNAMES_ALL???\n",
    "            self.cl_avail =set(item[0] for item in clnames)\n",
    "\n",
    "        else :\n",
    "            clnames=[el.description.split('-')[1] for el in self.wchkcls if el.value==True]\n",
    "            #aqui tambien va por si se eliminan todos los subclusters del mismo cluster. Solo lista los clusters\n",
    "            #self.cl_avail =sorted(set(item for item in clnames))\n",
    "            self.cl_avail =set(item for item in clnames)\n",
    "\n",
    "\n",
    "        #------------ DEFINIR LIMITES DE PLOT ---------------------\n",
    "\n",
    "        #buscar los minimos y maximos de los clusters\n",
    "        #debede haber una forma mas elegante de hacerlo. Como hago sliced elmultiindex con tuplas\n",
    "\n",
    "        lvxmin=np.empty(self.n_tot_clusters)\n",
    "        lvxmin.fill(np.nan)\n",
    "        lvymin=np.empty(self.n_tot_clusters)\n",
    "        lvymin.fill(np.nan)\n",
    "        lvxmax=np.empty(self.n_tot_clusters)\n",
    "        lvxmax.fill(np.nan)\n",
    "        lvymax=np.empty(self.n_tot_clusters)\n",
    "        lvymax.fill(np.nan)\n",
    "        lvvmin=np.empty(self.n_tot_clusters)\n",
    "        lvvmin.fill(np.nan)\n",
    "        lvvmax=np.empty(self.n_tot_clusters)\n",
    "        lvvmax.fill(np.nan)\n",
    "        lpmin =np.empty(self.n_tot_clusters)\n",
    "        lpmin.fill(np.nan)\n",
    "        lpmax= np.empty(self.n_tot_clusters)\n",
    "        lpmax.fill(np.nan)\n",
    "        n=0\n",
    "        for cl in clnames:\n",
    "            lvxmin[n],lvymin[n]= self.dfclvv[cl].min()\n",
    "            lvxmax[n],lvymax[n] = self.dfclvv[cl].max()\n",
    "            if not self.dfclvp_is_empty:\n",
    "                lvvmin[n],lpmin[n] = self.dfclvp[cl].min()\n",
    "                lvvmax[n],lpmax[n] = self.dfclvp[cl].max()\n",
    "\n",
    "            n+=1\n",
    "        vxmin=np.nanmin(lvxmin)\n",
    "        if np.isnan(vxmin):\n",
    "            vxmin=0\n",
    "        vymin = np.nanmin(lvymin)\n",
    "        if np.isnan(vymin):\n",
    "            vymin =0\n",
    "        vxmax = np.nanmax(lvxmax)\n",
    "        if np.isnan(vxmax):\n",
    "            vxmax=1\n",
    "        vymax = np.nanmax(lvymax)\n",
    "        if np.isnan(vymax):\n",
    "            vymax=1\n",
    "\n",
    "        if not self.dfclvp_is_empty:\n",
    "            vvmin = np.nanmin(lvvmin)\n",
    "            if np.isnan(vvmin):\n",
    "                vvmin=0\n",
    "            vvmax = np.nanmax(lvvmax)\n",
    "            if np.isnan(vvmax):\n",
    "                vvmax=1\n",
    "\n",
    "            pmin= np.nanmin(lpmin)\n",
    "            if np.isnan(pmin):\n",
    "                pmin=0\n",
    "            pmax = np.nanmax(lpmax)\n",
    "            if np.isnan(pmax):\n",
    "                pmax=1\n",
    "\n",
    "        if self.chkLimGlob.value:#plotear con limites globales o con los limites del cluster\n",
    "            self.axvv.set_xlim((self.vxminGlob, self.vxmaxGlob))\n",
    "            self.axvv.set_ylim((self.vyminGlob, self.vymaxGlob))\n",
    "            if not self.dfclvp_is_empty:\n",
    "                self.axvp.set_xlim((self.vvminGlob, self.vvmaxGlob))\n",
    "                self.axvp.set_ylim((self.pminGlob, self.pmaxGlob))\n",
    "        else:\n",
    "            self.axvv.set_xlim((vxmin, vxmax))\n",
    "            self.axvv.set_ylim((vymin, vymax))\n",
    "            if not self.dfclvp_is_empty:\n",
    "                self.axvp.set_xlim((vvmin, vvmax))\n",
    "                self.axvp.set_ylim((pmin, pmax))\n",
    "\n",
    "        #####################################\n",
    "        #               PLOTEAR             #\n",
    "        #####################################\n",
    "        for item in clnames:\n",
    "            #busca el cluster actual y devuelve el indice dentro de la lista de clusters donde lo encuentra\n",
    "            #es decir, asocia un numero unico a un nombre de cluster\n",
    "            #es para que el color de los clusters sea el mismo siempre\n",
    "            idxClName = [ncl_ for ncl_, clname_ in enumerate(self.clnames_all) if clname_ == item]\n",
    "            #self.fig.suptitle('Grupos de velocidad de viento y potencia', y=1)\n",
    "            # magnitud del vector\n",
    "\n",
    "            magni = round(\n",
    "                np.mean(\n",
    "                    np.sqrt(self.dfclvv[item].vx**2 +\n",
    "                            self.dfclvv[item].vy**2)),\n",
    "                1)  # magnitud de la vv\n",
    "\n",
    "            self.axvv.scatter(\n",
    "                self.dfclvv[item].vx,\n",
    "                self.dfclvv[item].vy,\n",
    "                s=pSize,\n",
    "                c=self.mapa_colores[idxClName],\n",
    "                alpha=1)\n",
    "\n",
    "#------------------------MOSTRAR TEXTO -----------------------------\n",
    "            if self.wradText.index == 0: #magnitud\n",
    "\n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    magni,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                       path_effects.Normal()])\n",
    "\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    text = self.axvp.text(\n",
    "                        self.dfclvp[item].vViento.mean(),\n",
    "                        self.dfclvp[item].Pw.mean(),\n",
    "                        magni,\n",
    "                        fontsize=self.fontsize,\n",
    "                        weight='bold',\n",
    "                        color='w',\n",
    "                        alpha=1,\n",
    "                        zorder=100,\n",
    "                        **self.fontNameCluster\n",
    "                    )\n",
    "                    text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                           path_effects.Normal()])\n",
    "\n",
    "            elif self.wradText.index == 1: #numero\n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    idxClName[0]+1,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                       path_effects.Normal()])\n",
    "\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    text = self.axvp.text(\n",
    "                        self.dfclvp[item].vViento.mean(),\n",
    "                        self.dfclvp[item].Pw.mean(),\n",
    "                        idxClName[0]+1,\n",
    "                        fontsize=self.fontsize,\n",
    "                        weight='bold',\n",
    "                        color='w',\n",
    "                        alpha=1,\n",
    "                        zorder=100,\n",
    "                        **self.fontNameCluster\n",
    "                    )\n",
    "                    text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                           path_effects.Normal()])\n",
    "\n",
    "            elif self.wradText.index == 2:\n",
    "                text = self.axvv.text(\n",
    "                    self.dfclvv[item].vx.mean(),\n",
    "                    self.dfclvv[item].vy.mean(),\n",
    "                    item,\n",
    "                    fontsize=self.fontsize,\n",
    "                    weight='bold',\n",
    "                    color='w',\n",
    "                    alpha=1,\n",
    "                    zorder=100,\n",
    "                    **self.fontNameCluster\n",
    "                )\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                       path_effects.Normal()])\n",
    "\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    text = self.axvp.text(\n",
    "                        self.dfclvp[item].vViento.mean(),\n",
    "                        self.dfclvp[item].Pw.mean(),\n",
    "                        item,\n",
    "                        fontsize=self.fontsize,\n",
    "                        weight='bold',\n",
    "                        color='w',\n",
    "                        alpha=1,\n",
    "                        zorder=100,\n",
    "                        **self.fontNameCluster\n",
    "                    )\n",
    "                    text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='k'),\n",
    "                                           path_effects.Normal()])\n",
    "\n",
    "        ######### MOSTRAR CENTROIDES#######################\n",
    "        if self.chkShowCnt.value:\n",
    "\n",
    "            for cl in self.cl_avail:\n",
    "\n",
    "                #el nombred el cluster esta en el indice\n",
    "                #le quito la letra con cl[1:] y dejo solo el numero como\n",
    "                #esta en el dataframe\n",
    "                numcl = int(cl[1:])\n",
    "                self.axvv.scatter(\n",
    "                    self.idx_centroids.loc[numcl].vx,\n",
    "                    self.idx_centroids.loc[numcl].vy,\n",
    "                    marker='X',\n",
    "                    edgecolor='black',\n",
    "                    linewidth=1,\n",
    "                    facecolor='yellow',\n",
    "                    s=self.markerSize)\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    self.axvp.scatter(\n",
    "                        self.idx_centroids.loc[numcl].vViento,\n",
    "                        self.idx_centroids.loc[numcl].Pw,\n",
    "                        marker='X',\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1,\n",
    "                        facecolor='yellow',\n",
    "                        s=self.markerSize)\n",
    "\n",
    "            ####### MOSTRAR CENTROIDES SUBCLUSTERS\n",
    "            if self.n_subclu > 0:\n",
    "                for el in clnames:\n",
    "                    self.axvv.scatter(\n",
    "                        self.idx_centroids_sc.loc[el].vx,\n",
    "                        self.idx_centroids_sc.loc[el].vy,\n",
    "                        marker='h',\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1,\n",
    "                        facecolor='aqua',\n",
    "                        s=self.markerSize)\n",
    "                    if not self.dfclvp_is_empty:\n",
    "                        self.axvp.scatter(\n",
    "                            self.idx_centroids_sc.loc[el].vViento,\n",
    "                            self.idx_centroids_sc.loc[el].Pw,\n",
    "                            marker='h',\n",
    "                            edgecolor='black',\n",
    "                            linewidth=1,\n",
    "                            facecolor='aqua',\n",
    "                            s=self.markerSize)\n",
    "\n",
    "        #MOSTRAR CURVA DEL FABRICANTE\n",
    "        if not self.dfclvp_is_empty:\n",
    "            if self.chkShowCPotFab.value:\n",
    "                self.axvp.plot(self.dfMfgCurve.index, self.dfMfgCurve.pw, c='red', label='Manufacturer')\n",
    "\n",
    "        #MOSTRAR LIMITE DE BETZ\n",
    "        if not self.dfclvp_is_empty:\n",
    "            if self.chkShowBetz.value:\n",
    "                self.axvp.plot(self.vvento,self.PMaxViento,label='Betz',c='y')\n",
    "\n",
    "        if not self.dfclvp_is_empty:\n",
    "            self.axvp.set_xlabel('Wind Speed [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "            self.axvp.set_ylabel('Power [W]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "            self.axvp.tick_params(axis='both', which='major')\n",
    "\n",
    "        self.axvv.set_xlabel('vx [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvv.set_ylabel('vy [m/s]',fontsize = self.labelFontSize, **self.fontNameLabel)\n",
    "        self.axvv.tick_params(axis='both', which='major')\n",
    "\n",
    "        #con esto cambio el texto de las thicks a el que defino en self.tick_font\n",
    "        for label in self.axvv.get_xticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "        for label in self.axvv.get_yticklabels():\n",
    "            label.set_fontproperties(self.ticks_font)\n",
    "\n",
    "        if not self.dfclvp_is_empty:\n",
    "            for label in self.axvp.get_xticklabels():\n",
    "                label.set_fontproperties(self.ticks_font)\n",
    "            for label in self.axvp.get_yticklabels():\n",
    "                label.set_fontproperties(self.ticks_font)\n",
    "        #MOSTRAR LEYENDA\n",
    "\n",
    "        if self.showLegends:\n",
    "            legCentroids = mlines.Line2D([], [], color='yellow', marker='X', linestyle='None',\n",
    "                                         markersize=10, label='Centroids',markeredgecolor='black',markeredgewidth=1.5)\n",
    "\n",
    "\n",
    "            if self.n_subclu > 0:\n",
    "                legSecCentroids = mlines.Line2D([], [], color='aqua', marker='h', linestyle='None',\n",
    "                                                markersize=10, label='Sec. centroids',markeredgecolor='black',markeredgewidth=1)\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    self.axvp.legend(handles=[legCentroids, legSecCentroids],facecolor = 'gainsboro',\n",
    "                                     frameon=True, loc='upper left')\n",
    "                self.axvv.legend(handles=[legCentroids, legSecCentroids],facecolor = 'gainsboro',\n",
    "                                 frameon=True, loc='upper right')\n",
    "            else:\n",
    "                self.axvv.legend(handles=[legCentroids],facecolor = 'gainsboro',frameon=True, loc='upper right')\n",
    "                if not self.dfclvp_is_empty:\n",
    "                    self.axvp.legend(handles=[legCentroids],facecolor = 'gainsboro',frameon=True, loc='upper left')\n",
    "\n",
    "        #self.fig.canvas.flush_events()\n",
    "        #plt.gcf()\n",
    "        #self.fig.canvas.draw()\n",
    "        plt.draw()\n",
    "        #self.save_plot(val)\n",
    "        #plt.show()\n",
    "        self.text_log.value = 'Plot actualizado.'\n",
    "        #imprimir a consola\n",
    "        os.write(1, b\"Plot actualizado\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataframe to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''TO DO: en el idx_centroids los numeros de los clusters no llevan la C, en el idx_centroids_sc si\n",
    "la llevan, o cambiar todo a que la lleven o que no la lleven'''\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from scipy.spatial.distance import cdist\n",
    "#crear clusters a partir de dataframes\n",
    "def dataframe_to_cluster(dfvxvy, n_clusters,dfVP =None, n_subclu=0, clusters_data=None,subclusters_data=None,\n",
    "                         datadir=None):\n",
    "    \"\"\"\n",
    "        Descripcion:\n",
    "        Esta funcion toma diferentes dataframes de entrada agrupa los datos por cluster.\n",
    "\n",
    "        :param subclusters_data: data to do subclustering [wind,pow,dir]\n",
    "        :param clusters_data: data to do clustering [wind,pow,dir]\n",
    "        :param dfvxvy: dataframe con columnas vx y vy\n",
    "        :param dfVP: dataframe con columnas de magnitud de viento y potencia\n",
    "        :param n_clusters: numero de clusters\n",
    "        :param n_subclu: Número de suclusters a calcular a partir de los n clusters calculados en un principio.\n",
    "                  Si n_subclu=0 no se calcula ningun subcluster. Por defecto n_sub=0\n",
    "\n",
    "\n",
    "        :return cl_ord: un array que contiene el número de cluster n ordenado de menor a mayor\n",
    "            de las magnitudes de la velocidad de viento sin tomar en cuenta la direccion\n",
    "        :return dfclvv: dataframe donde las componentes de velocidad de viento vx y vy estan\n",
    "            agrupadas por cluster\n",
    "        :return dfclpw: dataframe donde la potencia esta agrupada por cluster\n",
    "        :return dfclvp: dataframe donde la potencia y la magnitud de viento esta agrupada por\n",
    "            cluster\n",
    "    \"\"\"\n",
    "    #check if dataframe with power values exist\n",
    "    if dfVP is None:\n",
    "        dfvp_is_empty = True\n",
    "    else:\n",
    "        dfvp_is_empty = False\n",
    "    #'''- KMEANS -----------------------------------------------------------------------------------------'''\n",
    "    if clusters_data=='wind':\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfvxvy)\n",
    "        #buscar centroides en dataframes\n",
    "        #https://stackoverflow.com/questions/42583995/get-the-centroid-row-index-from-k-means-clustering-using-sklearn\n",
    "        min_dist = np.min(cdist(dfvxvy.values, kmeans.cluster_centers_, 'euclidean'), axis=1)#distancia minima a cada centroide\n",
    "        Y = pd.DataFrame(min_dist, index=dfvxvy.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(kmeans.labels_, index=dfvxvy.index, columns=['cluster_ID'])\n",
    "        #crea el dataframe\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "    if clusters_data=='pow' and not dfvp_is_empty:\n",
    "\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfVP)\n",
    "        #buscar centroides en dataframes\n",
    "        min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "        Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(kmeans.labels_, index=dfVP.index, columns=['cluster_ID'])\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "    elif clusters_data=='pow' and  dfvp_is_empty:\n",
    "\n",
    "        print('Power data is emtpy...')\n",
    "        return None\n",
    "\n",
    "    if clusters_data=='dir' and not dfvp_is_empty:\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(datadir)\n",
    "        #buscar centroides en dataframes\n",
    "        min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "        Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "        Z = pd.DataFrame(kmeans.labels_, index=dfVP.index, columns=['cluster_ID'])\n",
    "        PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "    elif clusters_data =='dir' and dfvp_is_empty:\n",
    "\n",
    "        print('Clustering with only direction and no power data not implemented yet.')\n",
    "        return None\n",
    "\n",
    "    #ordend e los cluster por magnitud de vv\n",
    "    cl_magni = np.zeros(n_clusters)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        vx = dfvxvy.vx.values[kmeans.labels_ == i]\n",
    "        vy = dfvxvy.vy.values[kmeans.labels_ == i]\n",
    "        cl_magni[i] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "    cl_ord = np.argsort(cl_magni.argsort()) #ver https://github.com/numpy/numpy/issues/8757\n",
    "\n",
    "    grouped = PAP.groupby(['cluster_ID'])#agrupa por numero de clusters las distancias minimas\n",
    "    idx_centroids = grouped.idxmin()#encuentra el indice de la distanciam minima\n",
    "    #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "    vxvy=dfvxvy.loc[idx_centroids.PCTimeStamp].values\n",
    "    if dfvp_is_empty:\n",
    "        idx_centroids=idx_centroids.assign(vx=vxvy[:,0],vy=vxvy[:,1])\n",
    "    else:\n",
    "        vvpot = dfVP.loc[idx_centroids.PCTimeStamp].values\n",
    "        idx_centroids=idx_centroids.assign(vx=vxvy[:,0],vy=vxvy[:,1],vViento=vvpot[:,0],Pw=vvpot[:,1])\n",
    "        idx_centroids.sort_values(by='vViento',inplace=True)# ordenar por velocidad de viento\n",
    "\n",
    "\n",
    "    idx_centroids.reset_index(inplace=True) #que ya no sea el cluster id el indice\n",
    "    idx_centroids.index.set_names('cluster_ID_ord',inplace=True)  #ponerle el nombre al indice ordenado\n",
    "    idx_centroids.index+=1 #paraque el indice empieze en uno y no exista cluster 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## CREAR MULTIINDICE ---------------------------------------------------------------'''\n",
    "    #CLUSTER VX,VY:\n",
    "    #https://stackoverflow.com/questions/37835508/how-to-do-multi-column-from-tuples\n",
    "    #nombre de las columnas del dataframe\n",
    "    if dfvp_is_empty:\n",
    "        colheadvv = []\n",
    "        for i in range(n_clusters):\n",
    "            colheadvv.append(('C' + str(i + 1), 'vx'))\n",
    "            colheadvv.append(('C' + str(i + 1), 'vy'))\n",
    "        dfclvv = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            dfclvv = pd.concat([\n",
    "                dfclvv, dfvxvy.vx[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]],\n",
    "                dfvxvy.vy[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]\n",
    "            ],\n",
    "                axis=1,\n",
    "                ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "    else:\n",
    "\n",
    "        colheadvv = []\n",
    "        colheadpw = []\n",
    "        for i in range(n_clusters):\n",
    "            colheadvv.append(('C' + str(i + 1), 'vx'))\n",
    "            colheadvv.append(('C' + str(i + 1), 'vy'))\n",
    "            colheadpw.append('C' + str(i + 1))\n",
    "        dfclvv = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            dfclvv = pd.concat([\n",
    "                dfclvv, dfvxvy.vx[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]],\n",
    "                dfvxvy.vy[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]\n",
    "            ],\n",
    "                axis=1,\n",
    "                ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "        #CLUSTER POTENCIA:\n",
    "        dfclpw = pd.DataFrame()\n",
    "        for i in range(n_clusters):\n",
    "            dfclpw = pd.concat([dfclpw, dfVP.Pw[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]],\n",
    "                               ignore_index=True,\n",
    "                               axis=1)\n",
    "        dfclpw.columns = colheadpw\n",
    "\n",
    "        #CLUSTER VIENTO POTENCIA:\n",
    "\n",
    "        colheadvp = []\n",
    "        for i in range(n_clusters):\n",
    "            colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "            colheadvp.append(('C' + str(i + 1), 'Pw'))\n",
    "        dfclvp = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            dfclvp = pd.concat([\n",
    "                dfclvp, dfVP.vViento[kmeans.labels_ == np.where(cl_ord ==i)[0][0]],\n",
    "                dfVP.Pw[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]]] ,\n",
    "                axis=1,\n",
    "                ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "\n",
    "    if clusters_data=='direccion':\n",
    "        #CLUSTER direccion viento\n",
    "        colheadvp = []\n",
    "        for i in range(n_clusters):\n",
    "            colheadvp.append(('C' + str(i + 1), 'Dir'))\n",
    "            colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "        dfcldv = pd.DataFrame()\n",
    "        for i in range(n_clusters):\n",
    "            dfcldv = pd.concat([\n",
    "                dfcldv, datadir.vViento[kmeans.labels_ ==( cl_ord ==i)],\n",
    "                datadir.Dir[kmeans.labels_ == (cl_ord ==i)]],\n",
    "                axis=1,ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfcldv.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "    '''- CALCULAR SUBCLUSTERS ------------------------------------------------------------------- '''\n",
    "\n",
    "\n",
    "    if n_subclu > 0:\n",
    "        scl_centroids = []\n",
    "        scl_labels = []\n",
    "        scl_ncentroids =[]\n",
    "        idx_centroids_sc= pd.DataFrame() #va almacenar los centroides de los subclusters\n",
    "        #obtener los resultados del clusterizado\n",
    "        for i in range(n_clusters):\n",
    "            if subclusters_data=='wind':\n",
    "                dfclvvnoNA=dfclvv['C'+str(i+1)].dropna()\n",
    "                #buscando centroides con los subclusters\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvvnoNA)\n",
    "                min_dist_sc = np.min(cdist(dfclvvnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                Y_sc = pd.DataFrame(min_dist_sc, index=dfclvvnoNA.index, columns=['PCTimeStamp'])\n",
    "                Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvvnoNA.index, columns=['subcluster_ID'])\n",
    "\n",
    "            elif subclusters_data=='pow':\n",
    "                dfclvpnoNA=dfclvp['C'+str(i+1)].dropna()\n",
    "                #buscando centroides con los subclusters\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvpnoNA)\n",
    "                min_dist_sc = np.min(cdist(dfclvpnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                Y_sc = pd.DataFrame(min_dist_sc, index=dfclvpnoNA.index, columns=['PCTimeStamp'])\n",
    "                Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvpnoNA.index, columns=['subcluster_ID'])\n",
    "            else:\n",
    "                print('Todavía no programado, haciendo subclusters en potencia')\n",
    "                kmeans_sc = cluster.KMeans(n_clusters=n_subclu, random_state=0).fit(dfclvp['C'+str(i+1)].dropna())\n",
    "\n",
    "            scl_centroids.append(kmeans_sc.cluster_centers_)\n",
    "            scl_labels.append(kmeans_sc.labels_)\n",
    "            scl_ncentroids.append(len(scl_centroids[i]))\n",
    "\n",
    "\n",
    "            PAP_sc = pd.concat([Y_sc,Z_sc], axis=1)\n",
    "            #poniendo index a los centroides de los subclusters\n",
    "            grouped_sc = PAP_sc.groupby(['subcluster_ID'])\n",
    "            idx_cent_sc = grouped_sc.idxmin()\n",
    "            idx_cent_sc.index +=1\n",
    "            #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "            vxvy_sc=dfvxvy.loc[idx_cent_sc.PCTimeStamp].values\n",
    "            vvpot_sc = dfVP.loc[idx_cent_sc.PCTimeStamp].values\n",
    "            idx_centroids_sc=pd.concat([idx_centroids_sc, idx_cent_sc.assign(vx=vxvy_sc[:,0],vy=vxvy_sc[:,1],vViento=vvpot_sc[:,0],\n",
    "                                                                             Pw=vvpot_sc[:,1], cluster_ID='C'+str(i+1))] )\n",
    "        #creando el multiindex fuera del ciclo for\n",
    "        # idx_centroids_sc.set_index(['cluster_ID',idx_centroids_sc.index],inplace=True)\n",
    "\n",
    "        idx_centroids_sc.reset_index(inplace=True)\n",
    "        idx_centroids_sc.sort_values(['cluster_ID','vViento'], ascending=[1,1],inplace=True)\n",
    "        lst_num_sc=list(range(1,n_subclu+1))*n_clusters#crea una lista de numeros para el subcluster [1,2,3..1,2,3]\n",
    "        sc_idx_list =list(map(lambda x:'SC'+str(x),lst_num_sc))#le pone las letras SC [SC1,SC2,SC3...SC1,SC2,SC3]\n",
    "        idx_centroids_sc=idx_centroids_sc.assign(subcluster_ID_ord=sc_idx_list)\n",
    "        idx_centroids_sc.set_index(['cluster_ID','subcluster_ID_ord'],inplace=True)\n",
    "\n",
    "        ############  ORDENAR CENTROIDES:  ordenar el orden de aparicion segun la magnitud de la vv\n",
    "        scl_magni = np.zeros([n_clusters,n_subclu])\n",
    "        scl_ord = []\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "\n",
    "            for j in range(n_subclu):\n",
    "\n",
    "                vx = dfclvv['C' + str(i+1)].vx.dropna().values[scl_labels[i] == j]\n",
    "                vy = dfclvv['C' + str(i+1)].vy.dropna().values[scl_labels[i] == j]\n",
    "                scl_magni[i][j] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "\n",
    "            scl_ord.append( scl_magni[i].argsort())# ver https://github.com/numpy/numpy/issues/8757\n",
    "\n",
    "        #ORDENAR CENTROIDES\n",
    "        for i in range(len(scl_centroids)):\n",
    "            scl_centroids[i] = scl_centroids[i][scl_ord[i]]\n",
    "\n",
    "        #CLUSTER VIENTO POTENCIA:\n",
    "        colheadvp = []\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'vViento'))\n",
    "                colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'Pw'))\n",
    "        dfsclvp = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclvp = pd.concat([\n",
    "                    dfsclvp, dfclvp['C'+str(i+1)].dropna().vViento[scl_labels[i]  == scl_ord[i][j]],\n",
    "                    dfclvp['C'+str(i+1)].dropna().Pw[scl_labels[i] == scl_ord[i][j]]\n",
    "                ],\n",
    "                    axis=1,\n",
    "                    ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfsclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "\n",
    "        #CLUSTER VX,VY:####################################################\n",
    "        colheadvv = []\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vx'))\n",
    "                colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vy'))\n",
    "        dfsclvv = pd.DataFrame()\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclvv = pd.concat([\n",
    "                    dfsclvv, dfclvv['C'+str(i+1)].dropna().vx[scl_labels[i]  == scl_ord[i][j]],\n",
    "                    dfclvv['C'+str(i+1)].dropna().vy[scl_labels[i] == scl_ord[i][j]]\n",
    "                ],\n",
    "                    axis=1,\n",
    "                    ignore_index=True)\n",
    "        #crear multiindice\n",
    "        dfsclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "        #CLUSTER POTENCIA:\n",
    "        dfsclpw = pd.DataFrame()\n",
    "        colheadpw =[]\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                colheadpw.append(('C' + str(i + 1),'SC' + str(j + 1)))\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(n_subclu):\n",
    "                dfsclpw = pd.concat([dfsclpw, dfclvp['C'+str(i+1)].Pw.dropna()[scl_labels[i] == scl_ord[i][j]]],\n",
    "                                    ignore_index=True,\n",
    "                                    axis=1)\n",
    "        dfsclpw.columns = pd.MultiIndex.from_tuples(colheadpw)\n",
    "\n",
    "        #### buscar centroides para la grafica vv\n",
    "        #obtener nombre de niveles\n",
    "        n_subclu = len(dfsclvv.columns.levels[1])\n",
    "        #numero total de clusters incluidos los subclusters\n",
    "        n_tot_clusters = n_subclu*n_clusters\n",
    "        # solo aplica cuando hay subclusters\n",
    "        lev0 = dfsclvv.columns.get_level_values(0)\n",
    "        lev1 = dfsclvv.columns.get_level_values(1)\n",
    "        namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "        colnames = namcl[::2]\n",
    "\n",
    "\n",
    "        return  dfsclvv,dfsclpw,dfsclvp,cl_ord,kmeans.cluster_centers_   , idx_centroids,scl_ord,scl_centroids,idx_centroids_sc\n",
    "\n",
    "    else:# sin subclusters\n",
    "        scl_ord=[]\n",
    "        scl_centroids=[]\n",
    "        idx_centroids_sc=[]\n",
    "        if dfvp_is_empty:\n",
    "            return dfclvv,[],[],cl_ord,kmeans.cluster_centers_,idx_centroids,scl_ord,scl_centroids, idx_centroids_sc\n",
    "        else:\n",
    "            return dfclvv,dfclpw,dfclvp,cl_ord,kmeans.cluster_centers_,idx_centroids,scl_ord,scl_centroids, idx_centroids_sc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Eliminar clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' FUNCION ACTUALIZADA A AGOSTO VER: https://pandas-docs.github.io/pandas-docs-travis/user_guide/advanced.html\n",
    "La palabra labels cambio a codes\n",
    "Changed in version 0.24.0: MultiIndex.labels has been renamed to MultiIndex.codes and MultiIndex.set_labels\n",
    "to MultiIndex.set_codes.\n",
    "'''\n",
    "'''TODO: POR ALGUNA RAZON NO PUEDO EJECUTAR LA MISMA FUNCION DOS VECES. ES COMO SI AFECTARA MIS VARIABLES ORIGINALES'''\n",
    "def del_clusters(data,cltodel,idx_cent,idx_cent_sc=None,scl_ord=None,cl_type='cluster'):\n",
    "    \"\"\"\n",
    "    Elimina clusters, subclusters, centroides de clusters o centroides de subclusters.\n",
    "        Argumentos:\n",
    "            dataf: dataframes a los que se eliminaran los clusters o subclusters.\n",
    "            cltodel: lista o listas de clusters o subclusters a eliminar\n",
    "            sc_centroids: lista que contiene los centroides. De esta lista se eliminaran los centroides\n",
    "                            a partir de cltodel.\n",
    "    \"\"\"\n",
    "    dflist =[]\n",
    "    for df in data:\n",
    "        dflist.append(df.drop(cltodel,axis=1))\n",
    "    #cambiar nombre por numero de centroides\n",
    "    n_cl=len(df.columns.levels[0])\n",
    "    n_subcl = len(df.columns.levels[1])\n",
    "    #numero total de clusters incluidos los subclusters\n",
    "    #sn_tot_clusters = (n_subcl*n_cl) -(len(df.columns.labels[0])-len(dflist[0].columns.labels[0]))/2\n",
    "    #sn_tot_clusters = (n_subcl*n_cl) -(len(df.columns.codes[0])-len(dflist[0].columns.codes[0]))/2\n",
    "    #eliminar centroides de clusters\n",
    "    clnames = pd.unique(df.columns.get_level_values(0))\n",
    "    lev0 = data[0].columns.get_level_values(0)\n",
    "    lev1 = data[0].columns.get_level_values(1)\n",
    "    namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "    cl_sc_names = namcl[::2]\n",
    "    #convertir a conjuntos\n",
    "    a =set(cltodel)# clusters a eliminar\n",
    "    b=set(cl_sc_names)#nombre de todos los clusters\n",
    "    c=(b-a)#a b lequito a\n",
    "    cent_restantes =set(sorted(set(int(item[0][1:]) for item in c)))#quito la letra C\n",
    "    idx_cent_reales = set(idx_cent.index.values)\n",
    "    idx_cent_todel = list(idx_cent_reales-cent_restantes)\n",
    "    idx_centroids_clean=idx_cent.drop(idx_cent_todel)\n",
    "\n",
    "    #eliminar centroides de los subclusters    \n",
    "    idx_centroidssc_clean = idx_cent_sc.drop(cltodel)\n",
    "  \n",
    "    return dflist,idx_centroids_clean,idx_centroidssc_clean\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# clusters a datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "datetime.datetime(2022, 3, 1, 17, 22, 53, 439969)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clust_to_data(dfv,dfvp):\n",
    "    \"\"\"\n",
    "    Convierte el dataframe de los datos de vx,vy y potencia separados en clusters (C1-SC1-vx,vy) a datos con\n",
    "    con tres columnas time,vx,vy o time,vv,pw.\n",
    "    To-do:   Sigue perdiendo miles de registros, ¿porque hay registros na en el original?\n",
    "    hay filas con solo nan en el original, en una prueba fueron como 4000\"\"\"\n",
    "    dfv= dfv.copy()#para que no afecte el original, si lo afecta el que esta como argumento\n",
    "    dfvp= dfvp.copy()\n",
    "    #Quitar multiindex\n",
    "    dfv.columns = dfv.columns.map(''.join)\n",
    "    dfv.reset_index(inplace=True)\n",
    "    #list comprehension\n",
    "    lvv=[\n",
    "       dfv.iloc[i].dropna().values\n",
    "       for i in range(len(dfv) )      \n",
    "      ]\n",
    "    dfvxvy_clean=pd.DataFrame(lvv,columns=['PCTimeStamp','vx','vy'])\n",
    "    dfvxvy_clean.dropna(inplace=True)#hay filas de nan y se pierden miles de datos, revisar\n",
    "    \n",
    "    #Quitar multiindex\n",
    "    dfvp.columns = dfvp.columns.map(''.join)\n",
    "    dfvp.reset_index(inplace=True)\n",
    "    #list comprehension\n",
    "    lvp=[\n",
    "       dfvp.iloc[i].dropna().values\n",
    "       for i in range(len(dfvp) )      \n",
    "      ]\n",
    "    dfvp_clean=pd.DataFrame(lvp,columns=['PCTimeStamp','vViento','Pw'])\n",
    "    dfvp_clean.dropna(inplace=True)#hay filas de nan y se pierden miles de datos, revisar\n",
    "    \n",
    "    return dfvxvy_clean,dfvp_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# daymin2date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "def daymin2date(year,day,hour_min):\n",
    "    \"\"\"\n",
    "\n",
    "    :param year: year when data was measured\n",
    "    :param day: day\n",
    "    :param hour_min: hour and minute in 24 hour format without separating character, e.g. 16:37 --> 1637\n",
    "    :return: timestamp in format dd/mm/YYYY HH:MM\n",
    "    \"\"\"\n",
    "    hourmin =hour_min.zfill(4)\n",
    "    hour = hourmin[:2]\n",
    "    minute = hourmin[2:]\n",
    "    res = datetime.datetime.strptime(year + \"-\" + day +\" \"+hour +\":\"+minute, \"%Y-%j %H:%M\").strftime(\"%d/%m/%Y %H:%M\")\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class kmData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "'''\n",
    "TO DO:\n",
    "-en el idx_centroids los numeros de los clusters no llevan la C, en el idx_centroids_sc si\n",
    "la llevan, o cambiar todo a que la lleven o que no la lleven\n",
    "'''\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class KMData:\n",
    "    \"\"\"\n",
    "    Clase para tener un objeto con todos los datos de los clusters.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kmeans_labels = None\n",
    "        self.dfclvv = None\n",
    "        self.cl_ord = None\n",
    "        self.scl_ord= None\n",
    "        self.scl_centroids = None\n",
    "        self.idx_centroids = None\n",
    "        self.idx_centroids_sc = None\n",
    "        self.cl_centers = None\n",
    "        self.dfclpw = None\n",
    "        self.dfclvp= None\n",
    "\n",
    "    #crear clusters a partir de dataframes\n",
    "    def dataframe_to_cluster(self,dfvxvy, n_clusters,dfVP =None, n_sub_clusters=0, clusters_data=None,\n",
    "                             subclusters_data=None, datadir=None):\n",
    "        \"\"\"\n",
    "            Descripcion:\n",
    "            Esta funcion toma diferentes dataframes de entrada agrupa los datos por cluster.\n",
    "\n",
    "            :param subclusters_data: data to do subclustering [wind,pow,dir]\n",
    "            :param clusters_data: data to do clustering [wind,pow,dir]\n",
    "            :param dfvxvy: dataframe con columnas vx y vy\n",
    "            :param dfVP: dataframe con columnas de magnitud de viento y potencia\n",
    "            :param n_clusters: numero de clusters\n",
    "            :param n_sub_clusters: Número de suclusters a calcular a partir de los n clusters calculados en un principio.\n",
    "                      Si n_sub_clusters=0 no se calcula ningun subcluster. Por defecto n_sub=0\n",
    "\n",
    "\n",
    "            :return cl_ord: un array que contiene el número de cluster n ordenado de menor a mayor\n",
    "                de las magnitudes de la velocidad de viento sin tomar en cuenta la direccion\n",
    "            :return dfclvv: dataframe donde las componentes de velocidad de viento vx y vy estan\n",
    "                agrupadas por cluster\n",
    "            :return dfclpw: dataframe donde la potencia esta agrupada por cluster\n",
    "            :return dfclvp: dataframe donde la potencia y la magnitud de viento esta agrupada por\n",
    "                cluster\n",
    "        \"\"\"\n",
    "\n",
    "        #inicializacion de variables internas\n",
    "        dfclpw = None\n",
    "        dfclvp = None\n",
    "        scl_ord = None\n",
    "        scl_centroids = None\n",
    "        idx_centroids_sc = None\n",
    "\n",
    "        #check if dataframe with power values exist\n",
    "        if dfVP is None:\n",
    "            dfvp_is_empty = True\n",
    "        else:\n",
    "            dfvp_is_empty = False\n",
    "\n",
    "        #'''- KMEANS -----------------------------------------------------------------------------------------'''\n",
    "        if clusters_data=='wind':\n",
    "            kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfvxvy)\n",
    "            #buscar centroides en dataframes\n",
    "            #https://stackoverflow.com/questions/42583995/get-the-centroid-row-index-from-k-means-clustering-using-sklearn\n",
    "            min_dist = np.min(cdist(dfvxvy.values, kmeans.cluster_centers_, 'euclidean'), axis=1)#distancia minima a cada centroide\n",
    "            Y = pd.DataFrame(min_dist, index=dfvxvy.index, columns=['PCTimeStamp'])\n",
    "            Z = pd.DataFrame(kmeans.labels_, index=dfvxvy.index, columns=['cluster_ID'])\n",
    "            #crea el dataframe\n",
    "            PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "        if clusters_data=='pow' and not dfvp_is_empty:\n",
    "\n",
    "            kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(dfVP)\n",
    "            #buscar centroides en dataframes\n",
    "            min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "            Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "            Z = pd.DataFrame(kmeans.labels_, index=dfVP.index, columns=['cluster_ID'])\n",
    "            PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "        elif clusters_data=='pow' and  dfvp_is_empty:\n",
    "\n",
    "            print('Power data is emtpy...')\n",
    "            return None\n",
    "\n",
    "        if clusters_data=='dir' and not dfvp_is_empty:\n",
    "            kmeans = cluster.KMeans(n_clusters=n_clusters,random_state=0).fit(datadir)\n",
    "            #buscar centroides en dataframes\n",
    "            min_dist = np.min(cdist(dfVP.values, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "            Y = pd.DataFrame(min_dist, index=dfVP.index, columns=['PCTimeStamp'])\n",
    "            Z = pd.DataFrame(kmeans.labels_, index=dfVP.index, columns=['cluster_ID'])\n",
    "            PAP = pd.concat([Y,Z], axis=1)\n",
    "\n",
    "        elif clusters_data =='dir' and dfvp_is_empty:\n",
    "\n",
    "            print('Clustering with only direction and no power data not implemented yet.')\n",
    "            return None\n",
    "\n",
    "        #ordend e los cluster por magnitud de vv\n",
    "        cl_magni = np.zeros(n_clusters)\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            vx = dfvxvy.vx.values[kmeans.labels_ == i]\n",
    "            vy = dfvxvy.vy.values[kmeans.labels_ == i]\n",
    "            cl_magni[i] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "        cl_ord = np.argsort(cl_magni.argsort()) #ver https://github.com/numpy/numpy/issues/8757\n",
    "\n",
    "        grouped = PAP.groupby(['cluster_ID'])#agrupa por numero de clusters las distancias minimas\n",
    "        idx_centroids = grouped.idxmin()#encuentra el indice de la distanciam minima\n",
    "        #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "        vxvy=dfvxvy.loc[idx_centroids.PCTimeStamp].values\n",
    "        if dfvp_is_empty:\n",
    "            idx_centroids=idx_centroids.assign(vx=vxvy[:,0],vy=vxvy[:,1])\n",
    "        else:\n",
    "            vvpot = dfVP.loc[idx_centroids.PCTimeStamp].values\n",
    "            idx_centroids=idx_centroids.assign(vx=vxvy[:,0],vy=vxvy[:,1],vViento=vvpot[:,0],Pw=vvpot[:,1])\n",
    "            idx_centroids.sort_values(by='vViento',inplace=True)# ordenar por velocidad de viento\n",
    "\n",
    "\n",
    "        idx_centroids.reset_index(inplace=True) #que ya no sea el cluster id el indice\n",
    "        idx_centroids.index.set_names('cluster_ID_ord',inplace=True)  #ponerle el nombre al indice ordenado\n",
    "        idx_centroids.index+=1 #paraque el indice empieze en uno y no exista cluster 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## CREAR MULTIINDICE ---------------------------------------------------------------'''\n",
    "        #CLUSTER VX,VY:\n",
    "        #https://stackoverflow.com/questions/37835508/how-to-do-multi-column-from-tuples\n",
    "        #nombre de las columnas del dataframe\n",
    "        if dfvp_is_empty:\n",
    "            colheadvv = []\n",
    "            for i in range(n_clusters):\n",
    "                colheadvv.append(('C' + str(i + 1), 'vx'))\n",
    "                colheadvv.append(('C' + str(i + 1), 'vy'))\n",
    "            dfclvv = pd.DataFrame()\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                dfclvv = pd.concat([\n",
    "                    dfclvv, dfvxvy.vx[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]],\n",
    "                    dfvxvy.vy[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]\n",
    "                ],\n",
    "                    axis=1,\n",
    "                    ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "        else:\n",
    "\n",
    "            colheadvv = []\n",
    "            colheadpw = []\n",
    "            for i in range(n_clusters):\n",
    "                colheadvv.append(('C' + str(i + 1), 'vx'))\n",
    "                colheadvv.append(('C' + str(i + 1), 'vy'))\n",
    "                colheadpw.append('C' + str(i + 1))\n",
    "            dfclvv = pd.DataFrame()\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                dfclvv = pd.concat([\n",
    "                    dfclvv, dfvxvy.vx[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]],\n",
    "                    dfvxvy.vy[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]\n",
    "                ],\n",
    "                    axis=1,\n",
    "                    ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "            #CLUSTER POTENCIA:\n",
    "            dfclpw = pd.DataFrame()\n",
    "            for i in range(n_clusters):\n",
    "                dfclpw = pd.concat([dfclpw, dfVP.Pw[kmeans.labels_ == np.where(cl_ord ==i)[0][0]]],\n",
    "                                   ignore_index=True,\n",
    "                                   axis=1)\n",
    "            dfclpw.columns = colheadpw\n",
    "\n",
    "            #CLUSTER VIENTO POTENCIA:\n",
    "\n",
    "            colheadvp = []\n",
    "            for i in range(n_clusters):\n",
    "                colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "                colheadvp.append(('C' + str(i + 1), 'Pw'))\n",
    "            dfclvp = pd.DataFrame()\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                dfclvp = pd.concat([\n",
    "                    dfclvp, dfVP.vViento[kmeans.labels_ == np.where(cl_ord ==i)[0][0]],\n",
    "                    dfVP.Pw[kmeans.labels_ ==np.where(cl_ord ==i)[0][0]]] ,\n",
    "                    axis=1,\n",
    "                    ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "\n",
    "        if clusters_data=='direccion':\n",
    "            #CLUSTER direccion viento\n",
    "            colheadvp = []\n",
    "            for i in range(n_clusters):\n",
    "                colheadvp.append(('C' + str(i + 1), 'Dir'))\n",
    "                colheadvp.append(('C' + str(i + 1), 'vViento'))\n",
    "            dfcldv = pd.DataFrame()\n",
    "            for i in range(n_clusters):\n",
    "                dfcldv = pd.concat([\n",
    "                    dfcldv, datadir.vViento[kmeans.labels_ ==( cl_ord ==i)],\n",
    "                    datadir.Dir[kmeans.labels_ == (cl_ord ==i)]],\n",
    "                    axis=1,ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfcldv.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "        '''- CALCULAR SUBCLUSTERS ------------------------------------------------------------------- '''\n",
    "        if n_sub_clusters > 0:\n",
    "            scl_centroids = []\n",
    "            scl_labels = []\n",
    "            scl_ncentroids =[]\n",
    "            idx_centroids_sc= pd.DataFrame() #va almacenar los centroides de los subclusters\n",
    "            #obtener los resultados del clusterizado\n",
    "            for i in range(n_clusters):\n",
    "                if subclusters_data=='wind':\n",
    "                    dfclvvnoNA=dfclvv['C'+str(i+1)].dropna()\n",
    "                    #buscando centroides con los subclusters\n",
    "                    kmeans_sc = cluster.KMeans(n_clusters=n_sub_clusters, random_state=0).fit(dfclvvnoNA)\n",
    "                    min_dist_sc = np.min(cdist(dfclvvnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                    Y_sc = pd.DataFrame(min_dist_sc, index=dfclvvnoNA.index, columns=['PCTimeStamp'])\n",
    "                    Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvvnoNA.index, columns=['subcluster_ID'])\n",
    "\n",
    "                elif subclusters_data=='pow':\n",
    "                    dfclvpnoNA=dfclvp['C'+str(i+1)].dropna()\n",
    "                    #buscando centroides con los subclusters\n",
    "                    kmeans_sc = cluster.KMeans(n_clusters=n_sub_clusters, random_state=0).fit(dfclvpnoNA)\n",
    "                    min_dist_sc = np.min(cdist(dfclvpnoNA.values, kmeans_sc.cluster_centers_, 'euclidean'), axis=1)\n",
    "                    Y_sc = pd.DataFrame(min_dist_sc, index=dfclvpnoNA.index, columns=['PCTimeStamp'])\n",
    "                    Z_sc = pd.DataFrame(kmeans_sc.labels_, index=dfclvpnoNA.index, columns=['subcluster_ID'])\n",
    "                else:\n",
    "                    print('Todavía no programado, haciendo subclusters en potencia')\n",
    "                    kmeans_sc = cluster.KMeans(n_clusters=n_sub_clusters, random_state=0).fit(dfclvp['C'+str(i+1)].dropna())\n",
    "\n",
    "                scl_centroids.append(kmeans_sc.cluster_centers_)\n",
    "                scl_labels.append(kmeans_sc.labels_)\n",
    "                scl_ncentroids.append(len(scl_centroids[i]))\n",
    "\n",
    "\n",
    "                PAP_sc = pd.concat([Y_sc,Z_sc], axis=1)\n",
    "                #poniendo index a los centroides de los subclusters\n",
    "                grouped_sc = PAP_sc.groupby(['subcluster_ID'])\n",
    "                idx_cent_sc = grouped_sc.idxmin()\n",
    "                idx_cent_sc.index +=1\n",
    "                #agregando columnas de velocidadd de viento y potencia al dataframe de los centroides\n",
    "                vxvy_sc=dfvxvy.loc[idx_cent_sc.PCTimeStamp].values\n",
    "                vvpot_sc = dfVP.loc[idx_cent_sc.PCTimeStamp].values\n",
    "                idx_centroids_sc=pd.concat([idx_centroids_sc, idx_cent_sc.assign(vx=vxvy_sc[:,0],vy=vxvy_sc[:,1],vViento=vvpot_sc[:,0],\n",
    "                                                                                 Pw=vvpot_sc[:,1], cluster_ID='C'+str(i+1))] )\n",
    "            #creando el multiindex fuera del ciclo for\n",
    "            # idx_centroids_sc.set_index(['cluster_ID',idx_centroids_sc.index],inplace=True)\n",
    "\n",
    "            idx_centroids_sc.reset_index(inplace=True)\n",
    "            idx_centroids_sc.sort_values(['cluster_ID','vViento'], ascending=[1,1],inplace=True)\n",
    "            lst_num_sc=list(range(1,n_sub_clusters+1))*n_clusters#crea una lista de numeros para el subcluster [1,2,3..1,2,3]\n",
    "            sc_idx_list =list(map(lambda x:'SC'+str(x),lst_num_sc))#le pone las letras SC [SC1,SC2,SC3...SC1,SC2,SC3]\n",
    "            idx_centroids_sc=idx_centroids_sc.assign(subcluster_ID_ord=sc_idx_list)\n",
    "            idx_centroids_sc.set_index(['cluster_ID','subcluster_ID_ord'],inplace=True)\n",
    "\n",
    "            ############  ORDENAR CENTROIDES:  ordenar el orden de aparicion segun la magnitud de la vv\n",
    "            scl_magni = np.zeros([n_clusters,n_sub_clusters])\n",
    "            scl_ord = []\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "\n",
    "                for j in range(n_sub_clusters):\n",
    "\n",
    "                    vx = dfclvv['C' + str(i+1)].vx.dropna().values[scl_labels[i] == j]\n",
    "                    vy = dfclvv['C' + str(i+1)].vy.dropna().values[scl_labels[i] == j]\n",
    "                    scl_magni[i][j] = np.mean(np.sqrt(vx**2 + vy**2))  #magnitud de la vv\n",
    "\n",
    "                scl_ord.append( scl_magni[i].argsort())# ver https://github.com/numpy/numpy/issues/8757\n",
    "\n",
    "            #ORDENAR CENTROIDES\n",
    "            for i in range(len(scl_centroids)):\n",
    "                scl_centroids[i] = scl_centroids[i][scl_ord[i]]\n",
    "\n",
    "            #CLUSTER VIENTO POTENCIA:\n",
    "            colheadvp = []\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'vViento'))\n",
    "                    colheadvp.append(('C' + str(i + 1),'SC' + str(j + 1), 'Pw'))\n",
    "            dfsclvp = pd.DataFrame()\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    dfsclvp = pd.concat([\n",
    "                        dfsclvp, dfclvp['C'+str(i+1)].dropna().vViento[scl_labels[i]  == scl_ord[i][j]],\n",
    "                        dfclvp['C'+str(i+1)].dropna().Pw[scl_labels[i] == scl_ord[i][j]]\n",
    "                    ],\n",
    "                        axis=1,\n",
    "                        ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfsclvp.columns = pd.MultiIndex.from_tuples(colheadvp)\n",
    "\n",
    "            #CLUSTER VX,VY:####################################################\n",
    "            colheadvv = []\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vx'))\n",
    "                    colheadvv.append(('C' + str(i + 1),'SC' + str(j + 1), 'vy'))\n",
    "            dfsclvv = pd.DataFrame()\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    dfsclvv = pd.concat([\n",
    "                        dfsclvv, dfclvv['C'+str(i+1)].dropna().vx[scl_labels[i]  == scl_ord[i][j]],\n",
    "                        dfclvv['C'+str(i+1)].dropna().vy[scl_labels[i] == scl_ord[i][j]]\n",
    "                    ],\n",
    "                        axis=1,\n",
    "                        ignore_index=True)\n",
    "            #crear multiindice\n",
    "            dfsclvv.columns = pd.MultiIndex.from_tuples(colheadvv)\n",
    "\n",
    "            #CLUSTER POTENCIA:\n",
    "            dfsclpw = pd.DataFrame()\n",
    "            colheadpw =[]\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    colheadpw.append(('C' + str(i + 1),'SC' + str(j + 1)))\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "                for j in range(n_sub_clusters):\n",
    "                    dfsclpw = pd.concat([dfsclpw, dfclvp['C'+str(i+1)].Pw.dropna()[scl_labels[i] == scl_ord[i][j]]],\n",
    "                                        ignore_index=True,\n",
    "                                        axis=1)\n",
    "            dfsclpw.columns = pd.MultiIndex.from_tuples(colheadpw)\n",
    "\n",
    "            #### buscar centroides para la grafica vv\n",
    "            #obtener nombre de niveles\n",
    "            n_sub_clusters = len(dfsclvv.columns.levels[1])\n",
    "            #numero total de clusters incluidos los subclusters\n",
    "            n_tot_clusters = n_sub_clusters*n_clusters\n",
    "            # solo aplica cuando hay subclusters\n",
    "            lev0 = dfsclvv.columns.get_level_values(0)\n",
    "            lev1 = dfsclvv.columns.get_level_values(1)\n",
    "            namcl = [(lev0[i],lev1[i]) for i in range(len(lev0))]\n",
    "            colnames = namcl[::2]\n",
    "\n",
    "\n",
    "\n",
    "        # llenado de datos\n",
    "        self.kmeans_labels = kmeans.labels_\n",
    "        self.comp_vel = dfclvv\n",
    "        self.cl_ord = cl_ord\n",
    "        self.idx_centroids = idx_centroids\n",
    "        self.cl_centers = kmeans.cluster_centers_\n",
    "        #self.dfclpw = dfclpw\n",
    "        self.dfclvp= dfclvp\n",
    "\n",
    "        self.scl_ord= scl_ord\n",
    "        self.scl_centroids = scl_centroids\n",
    "        self.idx_centroids_sc = idx_centroids_sc\n",
    "       "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "pycharm-a777efb8",
   "language": "python",
   "display_name": "PyCharm (aero)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}